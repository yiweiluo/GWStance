{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiweiluo/scientific-debates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "os.chdir('..')\n",
    "print(os.getcwd())\n",
    "from utils import get_fulltext,get_fname,fulltext_exists\n",
    "os.chdir('./data_processing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_AP</th>\n",
       "      <th>year</th>\n",
       "      <th>pretty_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"eat the babies\" viral video at aoc town hall ...</td>\n",
       "      <td>2019-10-04 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.buzzfeednews.com/article/passantino/extrem...</td>\n",
       "      <td>\"extremely likely\" global warming is man-made,...</td>\n",
       "      <td>2013-09-27 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shotofprevention.com/2010/11/03/history-makes-...</td>\n",
       "      <td>\"history\" makes headlines with launch of new w...</td>\n",
       "      <td>2020-03-13 14:32:02</td>\n",
       "      <td>https://shotofprevention/</td>\n",
       "      <td>pro</td>\n",
       "      <td>vax</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Shot of Prevention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/i...</td>\n",
       "      <td>\"it's global warming, stupid\" - buzzfeed news</td>\n",
       "      <td>2012-11-01 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"japan dropped an atomic bomb on america durin...</td>\n",
       "      <td>2014-02-24 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.buzzfeednews.com/article/llevin/opinion-im...</td>\n",
       "      <td>\"look at my record, child\": joe biden showed m...</td>\n",
       "      <td>2019-10-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.breitbart.com/politics/2019/06/14/orourke-...</td>\n",
       "      <td>\"president o'rourke will end oil and gas lease...</td>\n",
       "      <td>2019-06-14 00:00:00</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.buzzfeednews.com/article/andrewkaczynski/s...</td>\n",
       "      <td>smoking doesnt kill and other great old opeds ...</td>\n",
       "      <td>2015-03-31 00:00:00</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.foxnews.com/world/100-carbon-tax-by-2030-c...</td>\n",
       "      <td>$100 carbon tax by 2030 could save climate, sa...</td>\n",
       "      <td>2017-05-29 00:00:00</td>\n",
       "      <td>fox</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>childrenshealthdefense.org/news/4-billion-and-...</td>\n",
       "      <td>$4 billion and growing:  u.s. payouts for vacc...</td>\n",
       "      <td>2018-11-19 00:00:00</td>\n",
       "      <td>chd</td>\n",
       "      <td>anti</td>\n",
       "      <td>vax</td>\n",
       "      <td>None</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Children's Health Defense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "1      www.buzzfeednews.com/article/passantino/extrem...   \n",
       "2      shotofprevention.com/2010/11/03/history-makes-...   \n",
       "3      www.buzzfeednews.com/article/andrewkaczynski/i...   \n",
       "4      www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "5      www.buzzfeednews.com/article/llevin/opinion-im...   \n",
       "6      www.breitbart.com/politics/2019/06/14/orourke-...   \n",
       "7      www.buzzfeednews.com/article/andrewkaczynski/s...   \n",
       "8      www.foxnews.com/world/100-carbon-tax-by-2030-c...   \n",
       "21585  childrenshealthdefense.org/news/4-billion-and-...   \n",
       "\n",
       "                                                   title                 date  \\\n",
       "0      \"eat the babies\" viral video at aoc town hall ...  2019-10-04 00:00:00   \n",
       "1      \"extremely likely\" global warming is man-made,...  2013-09-27 00:00:00   \n",
       "2      \"history\" makes headlines with launch of new w...  2020-03-13 14:32:02   \n",
       "3          \"it's global warming, stupid\" - buzzfeed news  2012-11-01 00:00:00   \n",
       "4      \"japan dropped an atomic bomb on america durin...  2014-02-24 00:00:00   \n",
       "5      \"look at my record, child\": joe biden showed m...  2019-10-31 00:00:00   \n",
       "6      \"president o'rourke will end oil and gas lease...  2019-06-14 00:00:00   \n",
       "7      smoking doesnt kill and other great old opeds ...  2015-03-31 00:00:00   \n",
       "8      $100 carbon tax by 2030 could save climate, sa...  2017-05-29 00:00:00   \n",
       "21585  $4 billion and growing:  u.s. payouts for vacc...  2018-11-19 00:00:00   \n",
       "\n",
       "                          domain stance topic  is_AP    year  \\\n",
       "0                       buzzfeed    pro    cc   None  2019.0   \n",
       "1                       buzzfeed    pro    cc   None  2013.0   \n",
       "2      https://shotofprevention/    pro   vax  False  2020.0   \n",
       "3                       buzzfeed    pro    cc   None  2012.0   \n",
       "4                       buzzfeed    pro    cc   None  2014.0   \n",
       "5                       buzzfeed    pro    cc   None  2019.0   \n",
       "6                      breitbart   anti    cc   None  2019.0   \n",
       "7                       buzzfeed    pro    cc   None  2015.0   \n",
       "8                            fox   anti    cc   None  2017.0   \n",
       "21585                        chd   anti   vax   None  2018.0   \n",
       "\n",
       "                   pretty_domain  \n",
       "0                       Buzzfeed  \n",
       "1                       Buzzfeed  \n",
       "2             Shot of Prevention  \n",
       "3                       Buzzfeed  \n",
       "4                       Buzzfeed  \n",
       "5                       Buzzfeed  \n",
       "6                      Breitbart  \n",
       "7                       Buzzfeed  \n",
       "8                            Fox  \n",
       "21585  Children's Health Defense  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data_scraping/dedup_combined_df.pkl')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "* [Define functions](#Define-functions)\n",
    "* [Extract clausal complements with SpaCy](#Extract-embedded-clauses-with-SpaCy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a neural coref resolution step to the default SpaCy pipeline: https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x133fa2f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# First way we can control a parameter\n",
    "#neuralcoref.add_to_pipe(nlp, greedyness=0.75)\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for the main ```get_quotes``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_verb_dep(dep):\n",
    "    return dep[:3] == 'aux' or dep[:3] == 'adv' or dep == 'det' or dep == 'rel' or dep == 'prep' or dep[-3:] == 'obj' or dep[-3:] == 'mod' or dep == 'prt' or (dep[-4:] == 'comp' and dep != 'ccomp')\n",
    "\n",
    "def is_good_subj_dep(dep):\n",
    "    return dep != 'ccomp'\n",
    "\n",
    "def is_ROOT(tok):\n",
    "    return tok.dep_ == 'ROOT' or tok.dep_[-2:] == 'cl' or tok.dep_ == 'ccomp' or \\\n",
    "            (tok.dep_ == 'conj' and tok.head.dep_ == 'ROOT')\n",
    "\n",
    "REL_PRONOUNS = set(['who', 'whom', 'whose', 'which', 'that'])\n",
    "def is_rel_pronoun(tok):\n",
    "    tok = tok.lower().strip()\n",
    "    return tok in REL_PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_quotes(text):\n",
    "    # Do coref resolution\n",
    "    doc = nlp(text)\n",
    "    text = doc._.coref_resolved\n",
    "    \n",
    "    quote_objs = []\n",
    "    \n",
    "    for sent in sent_tokenize(text):#d.sents:\n",
    "        #print(sent)\n",
    "        sent = nlp(sent)\n",
    "        # Go through entire sentence, looking for verbs embedding a complement clause\n",
    "        VERBS = np.unique([token.head for token in sent if token.dep_ == 'ccomp'])\n",
    "        #print(VERBS)\n",
    "       \n",
    "        # Extract everything else for each VERB\n",
    "        for VERB in VERBS:\n",
    "            #print(\"\\nCcomp dependency found! For quoting verb '{}'\".format(VERB))\n",
    "            # Extract the rest of the quoting verb\n",
    "            verb_deps = [x for x in VERB.children if is_good_verb_dep(x.dep_)]\n",
    "            #print(\"\\tFound children:\",verb_deps)\n",
    "            for x in verb_deps:\n",
    "                new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                verb_deps.extend(new_children)\n",
    "                #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "            \n",
    "            # If verb's head is not itself (i.e., verb is not the ROOT), \n",
    "            # recursively trace back to ROOT, then add all children of ROOT\n",
    "            ROOT = VERB\n",
    "            while not is_ROOT(ROOT):\n",
    "                ROOT = ROOT.head\n",
    "                #print('\\t\\tCurrent root:',ROOT)\n",
    "            if VERB is not ROOT:\n",
    "                verb_deps.append(ROOT) \n",
    "                \n",
    "            #print(\"\\tAdding children of ROOT...\")\n",
    "            root_deps = [x for x in ROOT.children if is_good_verb_dep(x.dep_)]\n",
    "            #print(\"\\tFound ROOT deps:\",root_deps)\n",
    "            for x in root_deps:\n",
    "                new_children = [c for c in x.children if is_good_verb_dep(c.dep_)]\n",
    "                #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                root_deps.extend(new_children)\n",
    "                #print(\"\\tUpdated ROOT deps:\",root_deps)\n",
    "\n",
    "            #print(\"\\tAdding ROOT deps to verb deps...\")\n",
    "            verb_deps.extend([x for x in root_deps if x != VERB and x not in verb_deps])\n",
    "            #print(\"\\tUpdated verb deps:\",verb_deps)\n",
    "            \n",
    "            NEG,IS_NEG,neg_children = None,None,None\n",
    "            SUBJECT,subj_children = None,None\n",
    "                \n",
    "            #print(\"\\nLooking for SUBJECT and NEGATION(s)...\")\n",
    "            for child in ROOT.children:\n",
    "                if child.dep_[:5] == 'nsubj' or child.dep_ == 'expl':\n",
    "                    SUBJECT = child\n",
    "                    #print(\"\\tFound SUBJECT:\",SUBJECT)\n",
    "                    if SUBJECT.head.dep_ == 'relcl' and is_rel_pronoun(SUBJECT.text): # we're dealing with the subject of a rel clause\n",
    "                        #print(\"\\tFound quote inside a relative clause. Finding antecedent subject...\")\n",
    "                        SUBJECT = SUBJECT.head.head\n",
    "                        #print(\"\\tTrue subject:\",SUBJECT)\n",
    "                    #print(\"Subject token '{}' is in a coref cluster:\".format(SUBJECT),SUBJECT._.in_coref)\n",
    "                \n",
    "                if child.dep_[:3] == 'neg':\n",
    "                    NEG = child\n",
    "                    verb_deps.append(NEG)\n",
    "                    neg_children = [c for c in NEG.children if c != VERB]\n",
    "                    #print(\"n\\tAdding new NEG children:\",neg_children)\n",
    "                    for x in neg_children:\n",
    "                        new_children = [c for c in x.children]\n",
    "                        #print(\"\\tNew NEG grandchildren:\",new_children)\n",
    "                        neg_children.extend(new_children)\n",
    "                        #print(\"\\tUpdated neg_children:\",neg_children)\n",
    "                    verb_deps.extend(neg_children)\n",
    "                    #print(\"\\tUpdated verb_deps:\",verb_deps)\n",
    "                    IS_NEG = VERB in NEG.head.children or VERB == NEG.head\n",
    "            \n",
    "            if SUBJECT is None and (ROOT.dep_ == 'acl' or ROOT.dep_ == 'advcl'):\n",
    "                main_verb = ROOT.head\n",
    "                #print([(c.text,c.dep_) for c in main_verb.children])\n",
    "                SUBJS = [c for c in main_verb.children if c.dep_[:5] == 'nsubj' or c.dep_ == 'expl']\n",
    "                SUBJECT = SUBJS[0] if len(SUBJS) > 0 else None\n",
    "           \n",
    "            # Get rest of subject tokens\n",
    "            if SUBJECT is not None:\n",
    "                #print(\"\\nFound SUBJECT:\",SUBJECT)\n",
    "                #print(\"\\tAdding children of SUBJECT...\")\n",
    "                subj_children = [c for c in SUBJECT.children if is_good_subj_dep(c.dep_)]\n",
    "                #print(\"\\tFound children:\",subj_children)\n",
    "                for x in subj_children:\n",
    "                    new_children = [c for c in x.children if is_good_subj_dep(c.dep_)]\n",
    "                    #print(\"\\tAdding children of child {}:\".format(x.text),new_children)\n",
    "                    subj_children.extend(new_children)\n",
    "                    #print(\"\\tUpdated subject children:\",subj_children)\n",
    "\n",
    "            sorted_verb_tokens = sorted([(c,c.i) for c in verb_deps+[VERB]],key=lambda x:x[1])\n",
    "            #print(\"\\n\\tSorted verb tokens:\",sorted_verb_tokens)\n",
    "            if SUBJECT is not None:\n",
    "                sorted_subj_tokens = sorted([(c,c.i) for c in subj_children+[SUBJECT]],key=lambda x:x[1])\n",
    "                #print(\"\\tSorted subject tokens:\",sorted_subj_tokens)\n",
    "            else:\n",
    "                sorted_subj_tokens = None\n",
    "            if NEG is not None:\n",
    "                sorted_neg_tokens = sorted([(c,c.i) for c in neg_children+[NEG]],key=lambda x:x[1])\n",
    "            else:\n",
    "                sorted_neg_tokens = None\n",
    "\n",
    "            #print(\"\\nFinding quote introduced by '{}'...\".format(VERB))\n",
    "            emb_main_verbs = [c for c in VERB.children if c.dep_ == 'ccomp']\n",
    "            #print(\"\\tMain verbs of embedded clause:\",emb_main_verbs)\n",
    "            #assert len(emb_main_verbs) <= 2\n",
    "            for emb_main_verb in emb_main_verbs:\n",
    "                #print(\"\\tMain *verb*:\",emb_main_verb)\n",
    "\n",
    "                # Recursively get all children of main verb of embedded clause \n",
    "                #print(\"\\nRecursively getting children of main verb of embedded clause...\\n\")\n",
    "                #print(\"*\"*50)\n",
    "                children_queue = [x for x in emb_main_verb.children]\n",
    "                #print(\"\\tAdding children of main verb:\",children_queue)\n",
    "                for x in children_queue:\n",
    "                    new_children = [c for c in x.children]\n",
    "                    #print(\"\\tAdding children of {}:\".format(x.text),new_children)\n",
    "                    children_queue.extend(new_children)\n",
    "                    #print(\"\\tNew children queue:\",children_queue)\n",
    "\n",
    "                # Sort children and matrix verb to be in correct order\n",
    "                #print(\"\\nSorting tokens in quote...\")\n",
    "                children_and_indices = [(c,c.i) for c in children_queue+[emb_main_verb]]\n",
    "                sorted_ = sorted(children_and_indices,key=lambda x:x[1])\n",
    "                quote_objs.append({'quote':[tup[0].text for tup in sorted_],\n",
    "                        'verb tokens':[tup[0].text for tup in sorted_verb_tokens],\n",
    "                        'main verb':VERB.text,\n",
    "                       'subject tokens':[tup[0].text for tup in sorted_subj_tokens] if sorted_subj_tokens is not None else None,\n",
    "                       'main subject':SUBJECT.text if SUBJECT is not None else None,\n",
    "                       'neg tokens':[tup[0].text for tup in sorted_neg_tokens] if sorted_neg_tokens is not None else None,\n",
    "                       'main neg':NEG.text if NEG is not None else None,\n",
    "                       'is neg':IS_NEG})\n",
    "    \n",
    "    return quote_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract clausal complements with SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(Did this part on the cluster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.651726722717285"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## First 100 URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.buzzfeednews.com[SEP]article[SEP]tasneemnashrulla[SEP]eat-babies-aoc-town-hall-pro-trump-troll-larouche\tElapsed time in seconds: 0.05031239986419678\n"
     ]
    }
   ],
   "source": [
    "for url_ix in range(0,1):\n",
    "    start_time = time.time()\n",
    "    curr_url = df.url.values[url_ix]\n",
    "    quotes = get_quotes(get_fulltext(curr_url)[0])\n",
    "    fname = get_fname(curr_url)\n",
    "    with open('./extracted_quotes/{}.jsonlist'.format(fname),'w+') as f:\n",
    "        for res in quotes:\n",
    "            json.dump(res, f)\n",
    "            f.write('\\n')\n",
    "    print('{}\\tElapsed time in seconds:'.format(fname),(time.time()-start_time)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_url_ix = 1\n",
    "curr_url = df.url.values[curr_url_ix]\n",
    "quotes = get_quotes(get_fulltext(curr_url)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.buzzfeednews.com[SEP]article[SEP]tasneemnashrulla[SEP]eat-babies-aoc-town-hall-pro-trump-troll-larouche\n"
     ]
    }
   ],
   "source": [
    "fname = get_fname(curr_url)\n",
    "print(fname)\n",
    "with open('./extracted_quotes/{}.jsonlist'.format(fname),'w+') as f:\n",
    "    for res in quotes:\n",
    "        json.dump(res, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "{'quote': ['climate', 'change', 'is', 'a', 'hoax'], 'verb tokens': ['believes'], 'main verb': 'believes', 'subject tokens': ['the', 'pro', '-', 'Trump', 'LaRouche', 'PAC', ',', 'which', 'believes', ','], 'main subject': 'PAC', 'neg tokens': None, 'main neg': None, 'is neg': None}\n"
     ]
    }
   ],
   "source": [
    "with open('./extracted_quotes/{}.jsonlist'.format(fname),'r') as f:\n",
    "    data = f.readlines()\n",
    "    print(len(data))\n",
    "    \n",
    "read_quotes = [json.loads(q.strip()) for q in data]\n",
    "print(read_quotes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': ['climate', 'change', 'is', 'a', 'hoax', 'planted', 'the', 'troll'],\n",
       " 'verb tokens': ['believes'],\n",
       " 'main verb': 'believes',\n",
       " 'subject tokens': ['the',\n",
       "  'pro',\n",
       "  '-',\n",
       "  'Trump',\n",
       "  'LaRouche',\n",
       "  'PAC',\n",
       "  ',',\n",
       "  'which',\n",
       "  'believes'],\n",
       " 'main subject': 'PAC',\n",
       " 'neg tokens': None,\n",
       " 'main neg': None,\n",
       " 'is neg': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_quotes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval of extracted complement clauses from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WITH_NAMES = './extracted_quotes/'\n",
    "DIR_WITH_NOS = './extracted_quotes_2/'\n",
    "N_WITH_NAMES = 7433\n",
    "assert len(os.listdir(DIR_WITH_NAMES)) == N_WITH_NAMES\n",
    "FNAMES_WITH_NAMES = set(os.listdir(DIR_WITH_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Cool, we've extracted the comp clauses of all the first 7433 URLs. No re-indexing needed.\n",
    "for ix_url in range(0,N_WITH_NAMES):\n",
    "    url = df.url.values[ix_url]\n",
    "    fname = '{}.jsonlist'.format(get_fname(url))\n",
    "    assert fname in FNAMES_WITH_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_quotes_from_file(url_ix,df):\n",
    "    url = df.url.values[url_ix]\n",
    "    if url_ix < 7433:\n",
    "        fname = get_fname(url)\n",
    "        dir_ = 'extracted_quotes'\n",
    "    else:\n",
    "        fname = 'url_no_'+str(url_ix)\n",
    "        dir_ = 'extracted_quotes_2'\n",
    "    \n",
    "    with open('./{}/{}.jsonlist'.format(dir_,fname),'r') as f:\n",
    "        data = f.readlines()\n",
    "    quotes = []\n",
    "    for x in data:\n",
    "        res = json.loads(x.strip())\n",
    "        res.update({'source':url})                \n",
    "        quotes.append(res)\n",
    "    \n",
    "    return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote': ['climate', 'change', 'is', 'a', 'hoax'],\n",
       "  'verb tokens': ['believes'],\n",
       "  'main verb': 'believes',\n",
       "  'subject tokens': ['the',\n",
       "   'pro',\n",
       "   '-',\n",
       "   'Trump',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   ',',\n",
       "   'which',\n",
       "   'believes',\n",
       "   ','],\n",
       "  'main subject': 'PAC',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['climate', 'change', 'is', 'a', 'hoax', 'planted', 'the', 'troll'],\n",
       "  'verb tokens': ['believes'],\n",
       "  'main verb': 'believes',\n",
       "  'subject tokens': ['the',\n",
       "   'pro',\n",
       "   '-',\n",
       "   'Trump',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   ',',\n",
       "   'which',\n",
       "   'believes'],\n",
       "  'main subject': 'PAC',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['the',\n",
       "   'stunt',\n",
       "   'was',\n",
       "   'staged',\n",
       "   'by',\n",
       "   'what',\n",
       "   'is',\n",
       "   'now',\n",
       "   'a',\n",
       "   'far',\n",
       "   '-',\n",
       "   'right',\n",
       "   'pro',\n",
       "   '-',\n",
       "   'Trump',\n",
       "   'conspiracy',\n",
       "   'group',\n",
       "   'that',\n",
       "   'compares',\n",
       "   'climate',\n",
       "   'change',\n",
       "   'activism',\n",
       "   'to',\n",
       "   'â€œ',\n",
       "   'genocide'],\n",
       "  'verb tokens': ['turns', 'out'],\n",
       "  'main verb': 'turns',\n",
       "  'subject tokens': ['it'],\n",
       "  'main subject': 'it',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['that',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'â€™s',\n",
       "   'Green',\n",
       "   'New',\n",
       "   'Deal',\n",
       "   'was',\n",
       "   'not',\n",
       "   'enough',\n",
       "   'to',\n",
       "   'solve',\n",
       "   'the',\n",
       "   'climate',\n",
       "   'crisis'],\n",
       "  'verb tokens': ['saying'],\n",
       "  'main verb': 'saying',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['We',\n",
       "   'â€™re',\n",
       "   'not',\n",
       "   'going',\n",
       "   'to',\n",
       "   'be',\n",
       "   'here',\n",
       "   'for',\n",
       "   'much',\n",
       "   'long',\n",
       "   'because',\n",
       "   'of',\n",
       "   'the',\n",
       "   'climate',\n",
       "   'crisis'],\n",
       "  'verb tokens': ['said', 'addressing', 'Cortez'],\n",
       "  'main verb': 'said',\n",
       "  'subject tokens': ['Democratic',\n",
       "   'Rep.',\n",
       "   'Alexandria',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez'],\n",
       "  'main subject': 'Cortez',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['your',\n",
       "   'next',\n",
       "   'campaign',\n",
       "   'slogan',\n",
       "   'has',\n",
       "   'to',\n",
       "   'be',\n",
       "   'this',\n",
       "   ':',\n",
       "   \"'\",\n",
       "   'We',\n",
       "   'got',\n",
       "   'to',\n",
       "   'start',\n",
       "   'eating',\n",
       "   'babies'],\n",
       "  'verb tokens': ['think'],\n",
       "  'main verb': 'think',\n",
       "  'subject tokens': ['I'],\n",
       "  'main subject': 'I',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['Save', 'the', 'planet'],\n",
       "  'verb tokens': ['read', 'â€œ'],\n",
       "  'main verb': 'read',\n",
       "  'subject tokens': ['Democratic',\n",
       "   'Rep.',\n",
       "   'Alexandria',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'T',\n",
       "   '-',\n",
       "   'shirt',\n",
       "   ',',\n",
       "   'which',\n",
       "   'read',\n",
       "   'â€œ'],\n",
       "  'main subject': 'shirt',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['we', 'only', 'have', 'a', 'few', 'months', 'left'],\n",
       "  'verb tokens': ['loses',\n",
       "   'mind',\n",
       "   'over',\n",
       "   'change',\n",
       "   'during',\n",
       "   'townhall',\n",
       "   'claims'],\n",
       "  'main verb': 'claims',\n",
       "  'subject tokens': ['One', 'of', 'Ocasio', '-', 'Cortez', 'constituents'],\n",
       "  'main subject': 'One',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['One',\n",
       "   'of',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'constituents',\n",
       "   'loses',\n",
       "   'Democratic',\n",
       "   'Rep.',\n",
       "   'Alexandria',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'mind',\n",
       "   'over',\n",
       "   'climate',\n",
       "   'change',\n",
       "   'during',\n",
       "   'AOC',\n",
       "   \"'s\",\n",
       "   'townhall',\n",
       "   ',',\n",
       "   'claims',\n",
       "   'we',\n",
       "   'only',\n",
       "   'have',\n",
       "   'a',\n",
       "   'few',\n",
       "   'months',\n",
       "   'left'],\n",
       "  'verb tokens': ['got', 'to', 'start', 'eating', 'babies'],\n",
       "  'main verb': 'got',\n",
       "  'subject tokens': ['we'],\n",
       "  'main subject': 'we',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['the', 'world', 'is', 'coming', 'to', 'an', 'end'],\n",
       "  'verb tokens': ['has', 'whipped', 'up', 'supporters', 'into', 'thinking'],\n",
       "  'main verb': 'thinking',\n",
       "  'subject tokens': ['the',\n",
       "   'one',\n",
       "   'that',\n",
       "   'has',\n",
       "   'whipped',\n",
       "   'up',\n",
       "   'your',\n",
       "   'supporters',\n",
       "   'into',\n",
       "   'thinking'],\n",
       "  'main subject': 'one',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['people', 'must', 'â€œ', 'start', 'eating', 'babies'],\n",
       "  'verb tokens': ['blasts',\n",
       "   'AOC',\n",
       "   'over',\n",
       "   'how',\n",
       "   'handled',\n",
       "   'supporter',\n",
       "   'saying'],\n",
       "  'main verb': 'saying',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['that',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'was',\n",
       "   'concerned',\n",
       "   'the',\n",
       "   'woman',\n",
       "   'at',\n",
       "   'the',\n",
       "   'town',\n",
       "   'hall'],\n",
       "  'verb tokens': ['later', 'tweeted'],\n",
       "  'main verb': 'tweeted',\n",
       "  'subject tokens': ['Ocasio', '-', 'Cortez'],\n",
       "  'main subject': 'Cortez',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['was',\n",
       "   'â€œ',\n",
       "   'suffering',\n",
       "   'from',\n",
       "   'a',\n",
       "   'mental',\n",
       "   'condition',\n",
       "   'â€',\n",
       "   'and',\n",
       "   'that',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'wanted',\n",
       "   'to',\n",
       "   'treat',\n",
       "   'Ocasio',\n",
       "   '-',\n",
       "   'Cortez',\n",
       "   'with',\n",
       "   'compassion'],\n",
       "  'verb tokens': ['later', 'tweeted'],\n",
       "  'main verb': 'tweeted',\n",
       "  'subject tokens': ['Ocasio', '-', 'Cortez'],\n",
       "  'main subject': 'Cortez',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['climate',\n",
       "   'change',\n",
       "   'is',\n",
       "   'a',\n",
       "   'hoax',\n",
       "   'and',\n",
       "   'compares',\n",
       "   'carbon',\n",
       "   'dioxide',\n",
       "   'reduction',\n",
       "   'policies',\n",
       "   'to',\n",
       "   'â€œ',\n",
       "   'genocide'],\n",
       "  'verb tokens': ['believes'],\n",
       "  'main verb': 'believes',\n",
       "  'subject tokens': ['a',\n",
       "   'group',\n",
       "   'called',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   'â€”',\n",
       "   'which',\n",
       "   'is',\n",
       "   'affiliated',\n",
       "   'with',\n",
       "   'people',\n",
       "   'with',\n",
       "   'a',\n",
       "   'long',\n",
       "   'history',\n",
       "   'of',\n",
       "   'peddling',\n",
       "   'unfounded',\n",
       "   'conspiracy',\n",
       "   'theories',\n",
       "   'that',\n",
       "   'has',\n",
       "   'now',\n",
       "   'turned'],\n",
       "  'main subject': 'group',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': [',', 'AOC', 'does', \"n't\", 'rule', 'out', 'eating', 'babies'],\n",
       "  'verb tokens': ['said', 'on', 'Twitter'],\n",
       "  'main verb': 'said',\n",
       "  'subject tokens': ['a',\n",
       "   'group',\n",
       "   'called',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   'â€”',\n",
       "   'which',\n",
       "   'is',\n",
       "   'affiliated',\n",
       "   'with',\n",
       "   'people',\n",
       "   'with',\n",
       "   'a',\n",
       "   'long',\n",
       "   'history',\n",
       "   'of',\n",
       "   'peddling',\n",
       "   'unfounded',\n",
       "   'conspiracy',\n",
       "   'theories',\n",
       "   'that',\n",
       "   'has',\n",
       "   'now',\n",
       "   'turned'],\n",
       "  'main subject': 'group',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['â€œ',\n",
       "   'Turns',\n",
       "   'out',\n",
       "   'the',\n",
       "   'woman',\n",
       "   'at',\n",
       "   'the',\n",
       "   'town',\n",
       "   'hall',\n",
       "   'yelling',\n",
       "   'was',\n",
       "   'a',\n",
       "   'Trump',\n",
       "   'supporter',\n",
       "   'ðŸ¤·',\n",
       "   'ðŸ½\\u200d',\n",
       "   'â™€',\n",
       "   'ï¸.',\n",
       "   'â€',\n",
       "   'The',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   'has',\n",
       "   'been',\n",
       "   'running',\n",
       "   'an',\n",
       "   'â€œ',\n",
       "   'Eat',\n",
       "   'the',\n",
       "   'Children',\n",
       "   'â€',\n",
       "   'campaign',\n",
       "   'modeled',\n",
       "   'on',\n",
       "   'Jonathan',\n",
       "   'Swift',\n",
       "   'â€™s',\n",
       "   'satirical',\n",
       "   '1729',\n",
       "   'essay',\n",
       "   'A',\n",
       "   'Modest',\n",
       "   'Proposal',\n",
       "   ',',\n",
       "   'which',\n",
       "   'attempted',\n",
       "   'to',\n",
       "   'highlight',\n",
       "   'England',\n",
       "   'â€™s',\n",
       "   'exploitation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'impoverished',\n",
       "   'Irish',\n",
       "   'by',\n",
       "   'suggesting',\n",
       "   'that',\n",
       "   'poor',\n",
       "   'Irish',\n",
       "   'families',\n",
       "   'sell',\n",
       "   'poor',\n",
       "   'Irish',\n",
       "   'families',\n",
       "   'children',\n",
       "   'as',\n",
       "   'food',\n",
       "   'to',\n",
       "   'wealthy',\n",
       "   'landlords'],\n",
       "  'verb tokens': ['later', 'said', 'in', 'a', 'tweet'],\n",
       "  'main verb': 'said',\n",
       "  'subject tokens': ['Ocasio', '-', 'Cortez'],\n",
       "  'main subject': 'Cortez',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['â€œ',\n",
       "   'Turns',\n",
       "   'out',\n",
       "   'the',\n",
       "   'woman',\n",
       "   'at',\n",
       "   'the',\n",
       "   'town',\n",
       "   'hall',\n",
       "   'yelling',\n",
       "   'was',\n",
       "   'a',\n",
       "   'Trump',\n",
       "   'supporter',\n",
       "   'ðŸ¤·',\n",
       "   'ðŸ½\\u200d',\n",
       "   'â™€',\n",
       "   'ï¸.',\n",
       "   'â€',\n",
       "   'The',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   'has',\n",
       "   'been',\n",
       "   'running',\n",
       "   'an',\n",
       "   'â€œ',\n",
       "   'Eat',\n",
       "   'the',\n",
       "   'Children',\n",
       "   'â€',\n",
       "   'campaign',\n",
       "   'modeled',\n",
       "   'on',\n",
       "   'Jonathan',\n",
       "   'Swift',\n",
       "   'â€™s'],\n",
       "  'verb tokens': ['satirical', 'essay', 'A', 'Proposal'],\n",
       "  'main verb': 'essay',\n",
       "  'subject tokens': ['1729'],\n",
       "  'main subject': '1729',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['that',\n",
       "   'poor',\n",
       "   'Irish',\n",
       "   'families',\n",
       "   'sell',\n",
       "   'poor',\n",
       "   'Irish',\n",
       "   'families',\n",
       "   'children',\n",
       "   'as',\n",
       "   'food',\n",
       "   'to',\n",
       "   'wealthy',\n",
       "   'landlords'],\n",
       "  'verb tokens': ['attempted',\n",
       "   'to',\n",
       "   'highlight',\n",
       "   'exploitation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'impoverished',\n",
       "   'Irish',\n",
       "   'by',\n",
       "   'suggesting'],\n",
       "  'main verb': 'suggesting',\n",
       "  'subject tokens': ['A',\n",
       "   'Modest',\n",
       "   'Proposal',\n",
       "   ',',\n",
       "   'which',\n",
       "   'attempted',\n",
       "   'to',\n",
       "   'highlight',\n",
       "   'England',\n",
       "   'â€™s',\n",
       "   'exploitation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'impoverished',\n",
       "   'Irish',\n",
       "   'by',\n",
       "   'suggesting'],\n",
       "  'main subject': 'Proposal',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['if', 'the', 'town', 'hall', 'speaker', 'was', 'a', 'plant'],\n",
       "  'verb tokens': ['wondering'],\n",
       "  'main verb': 'wondering',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['Malthusianism', 'is', 'nâ€™t', 'new'],\n",
       "  'verb tokens': ['knew', 'that'],\n",
       "  'main verb': 'knew',\n",
       "  'subject tokens': ['Jonathan', 'Swift'],\n",
       "  'main subject': 'Swift',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['Facebook',\n",
       "   '/',\n",
       "   'Daniel',\n",
       "   'Burke',\n",
       "   '  ',\n",
       "   'is',\n",
       "   'a',\n",
       "   'LaRouche',\n",
       "   'PAC',\n",
       "   'â€“'],\n",
       "  'verb tokens': ['says'],\n",
       "  'main verb': 'says',\n",
       "  'subject tokens': ['Burke', 'â€”', 'who', 'says'],\n",
       "  'main subject': 'â€”',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['independent',\n",
       "   'candidate',\n",
       "   'for',\n",
       "   'the',\n",
       "   'US',\n",
       "   'Senate',\n",
       "   'â€”',\n",
       "   'bragged',\n",
       "   'about',\n",
       "   'Trump',\n",
       "   'giving',\n",
       "   'attention',\n",
       "   'to',\n",
       "   'Trump'],\n",
       "  'verb tokens': ['endorsed'],\n",
       "  'main verb': 'endorsed',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['the',\n",
       "   'connection',\n",
       "   'between',\n",
       "   'the',\n",
       "   'town',\n",
       "   'hall',\n",
       "   'troll',\n",
       "   'and',\n",
       "   'the',\n",
       "   'groupLaRouche',\n",
       "   'â€™s',\n",
       "   'modus',\n",
       "   'operandi'],\n",
       "  'verb tokens': ['first', 'made'],\n",
       "  'main verb': 'made',\n",
       "  'subject tokens': ['Matthew',\n",
       "   'Sweet',\n",
       "   ',',\n",
       "   'a',\n",
       "   'BBC',\n",
       "   'Radio',\n",
       "   '3',\n",
       "   'presenter',\n",
       "   'and',\n",
       "   'author',\n",
       "   'of',\n",
       "   'Operation',\n",
       "   'Chaos',\n",
       "   ',',\n",
       "   'which',\n",
       "   'explores',\n",
       "   'LaRouche',\n",
       "   'â€™s',\n",
       "   'conspiracy',\n",
       "   'theories',\n",
       "   ','],\n",
       "  'main subject': 'Sweet',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['the', 'Queen', 'controls'],\n",
       "  'verb tokens': ['In',\n",
       "   'a',\n",
       "   'thread',\n",
       "   'about',\n",
       "   'the',\n",
       "   'origins',\n",
       "   'of',\n",
       "   'the',\n",
       "   'â€œ',\n",
       "   'bizarre',\n",
       "   'political',\n",
       "   'cult',\n",
       "   'â€”',\n",
       "   'believes'],\n",
       "  'main verb': 'believes',\n",
       "  'subject tokens': None,\n",
       "  'main subject': None,\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['that',\n",
       "   'the',\n",
       "   'group',\n",
       "   'has',\n",
       "   'been',\n",
       "   'pulling',\n",
       "   'similar',\n",
       "   'stunts',\n",
       "   'for',\n",
       "   'the',\n",
       "   'past',\n",
       "   '50',\n",
       "   'years'],\n",
       "  'verb tokens': ['explained'],\n",
       "  'main verb': 'explained',\n",
       "  'subject tokens': ['the', 'international', 'drug', 'trade', 'â€”', 'Sweet'],\n",
       "  'main subject': 'Sweet',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['LaRouchies',\n",
       "   'have',\n",
       "   'been',\n",
       "   'enemies',\n",
       "   'of',\n",
       "   'the',\n",
       "   'green',\n",
       "   'movement',\n",
       "   'for',\n",
       "   'decades'],\n",
       "  'verb tokens': ['wrote', 'adding'],\n",
       "  'main verb': 'wrote',\n",
       "  'subject tokens': ['Sweet'],\n",
       "  'main subject': 'Sweet',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['that',\n",
       "   'they',\n",
       "   'carried',\n",
       "   'signs',\n",
       "   'like',\n",
       "   'â€œ',\n",
       "   'Feed',\n",
       "   'Jane',\n",
       "   'Fonda',\n",
       "   'to',\n",
       "   'the',\n",
       "   'whales'],\n",
       "  'verb tokens': ['adding'],\n",
       "  'main verb': 'adding',\n",
       "  'subject tokens': ['Sweet'],\n",
       "  'main subject': 'Sweet',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'},\n",
       " {'quote': ['LaRouchies',\n",
       "   'are',\n",
       "   'now',\n",
       "   'firm',\n",
       "   'Trump',\n",
       "   'supporters',\n",
       "   'â€”',\n",
       "   'though',\n",
       "   'former',\n",
       "   'Democratic',\n",
       "   'presidential',\n",
       "   'candidate',\n",
       "   'Michael',\n",
       "   'Dukakis',\n",
       "   'is',\n",
       "   'firm',\n",
       "   'Trump',\n",
       "   'supporters',\n",
       "   'first',\n",
       "   'love'],\n",
       "  'verb tokens': ['said'],\n",
       "  'main verb': 'said',\n",
       "  'subject tokens': ['Sweet'],\n",
       "  'main subject': 'Sweet',\n",
       "  'neg tokens': None,\n",
       "  'main neg': None,\n",
       "  'is neg': None,\n",
       "  'source': 'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quotes_from_file(0,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes_with_lemma(lemma,quote_list):\n",
    "    return [q for q in quote_list if lemmatizer.lemmatize(q['main verb'].lower()) == lemma]\n",
    "\n",
    "def get_quotes_with_stem(stem_set,quote_list):\n",
    "    return [q for q in quote_list if ps.stem(q['main verb'].lower()) in stem_set]\n",
    "\n",
    "def get_quotes_without_stem(stem_set,quote_list):\n",
    "    return [q for q in quote_list if ps.stem(q['main verb'].lower()) not in stem_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to true indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with question verb\n",
    "\n",
    "QUESTION_WORDS = set(['who','what','when','where','why','how','if','whose','whether','which','whom','whence'])\n",
    "QUESTION_VERBS = set(['ask','wonder','figure','guess','inquire','interrogate','question'])\n",
    "\n",
    "def has_indirect_question(quote_obj):\n",
    "    quote = quote_obj['quote']\n",
    "    first_word = quote[0].lower()\n",
    "    return first_word in QUESTION_WORDS\n",
    "\n",
    "def has_question_verb(quote_obj):\n",
    "    verb = quote_obj['main verb'].lower()\n",
    "    return verb in QUESTION_VERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside quotes with 'be' as main verb\n",
    "\n",
    "BE_STEMS = set(['is','wa','â€™s','are',\"'s\",'be','â€™m','am','are','â€™re',\"'m\",\"'re\"])\n",
    "\n",
    "quotes_without_be = get_quotes_without_stem(BE_STEMS,all_quotes)\n",
    "len(quotes_without_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with 'point' but not 'point_out' as main verb\n",
    "\n",
    "point_quotes = get_quotes_with_stem(['point'],all_quotes)\n",
    "point_out_quotes = [x for x in point_quotes if 'out' in x['verb tokens']]\n",
    "\n",
    "true_point_out_quotes = []\n",
    "false_point_out_quotes = []\n",
    "for x in point_out_quotes:\n",
    "    indices_out = [i for i,t in enumerate(x['verb tokens']) if t.lower() == 'out']\n",
    "    prev_toks = [ps.stem(x['verb tokens'][i-1].lower()) for i in indices_out]\n",
    "    if 'point' in prev_toks:\n",
    "        true_point_out_quotes.append(x)\n",
    "    else:\n",
    "        false_point_out_quotes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with a set of non-attributive verbs introducing comp clause\n",
    "OTHER_VERBS = set(['make','made','cause','caus','ensur','like','love',\n",
    "                    'help','mean','get','got','let','allow','want','becam',\n",
    "                    'becom','go','goe','lead'])\n",
    "\n",
    "non_other_verb_quotes = get_quotes_without_stem(OTHER_VERBS,all_quotes)\n",
    "len(non_other_verb_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes with 'seem', 'appear' as main verb\n",
    "\n",
    "non_seem_quotes = get_quotes_without_stem(['seem','appear'],all_quotes)\n",
    "len(non_seem_quotes)+len(seem_quotes),len(all_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine distribution of indirect statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common main verbs, subjects, amount of negation, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add lemma, stem info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add NER tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
