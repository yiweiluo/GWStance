{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from dateutil.parser import parse\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from urllib.error import URLError\n",
    "\n",
    "def soupify(url):\n",
    "    if url[:8] != 'https://':\n",
    "        url = 'https://'+url\n",
    "        \n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "        con = urllib.request.urlopen( req )\n",
    "        html = con.read()\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        return soup\n",
    "    except URLError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "* [Get URLs](#Get-URLs)\n",
    "    * [Climate change](#Climate-change)\n",
    "        * [URLs from search](#URLs-from-search)\n",
    "        * [MediaCloud URLs](#MediaCloud-urls)\n",
    "        * [Reid Google search URLs](#Reid-Urls)\n",
    "    * [Vaccines](#Vaccines)\n",
    "* [Post-processing](#Post-processing)\n",
    "    * [Filter out non-(relevant)-article URLs](#Filter-out-non-(relevant)-article-URLs)\n",
    "    * [Check consistency of coding](#Check-consistency-of-coding)\n",
    "    * [Deduplicate](#Dedup)\n",
    "* [Scraping fulltext and missing meta info](#Scraping-fulltext-and-missing-meta-info)\n",
    "* [Dedup via title similarity](#Dedup-via-title-similarity)\n",
    "* [Summary stats](#Summary-stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use SerpApi (https://serpapi.com/search-api) to scrape Google search results from querying climate change-related keywords on various websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SERP_API_KEY = \"481df24348cbec5d00f65baa55986d30b3b1ef2b09c5ab9de0f667dd43ce51d2\"\n",
    "from serpapi.google_search_results import GoogleSearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following query parameters restrict searches to desktop, US-based, English-language results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_params = {\"location\":\"United States\", \"device\":\"desktop\", \"hl\":\"en\", \"gl\":\"us\", \"serp_api_key\":SERP_API_KEY}\n",
    "client = GoogleSearchResults(query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def do_serpapi(domain,keyword):\n",
    "    keyword = keyword.replace('_',' ').replace('+',' ').replace('-',' ')\n",
    "    client.params_dict[\"q\"] = \"site:{} {}\".format(domain,keyword) # Update query to restrict to particular site\n",
    "    print('Searching w/ query: {}...'.format(client.params_dict[\"q\"]))\n",
    "    page_no = 1 \n",
    "    client.params_dict[\"start\"] = (page_no-1)*10                  # Update pagination\n",
    "    \n",
    "    dict_list = []\n",
    "    while 'error' not in client.get_dict(): # Get results as long as more pages exist\n",
    "        dict_list.append(client.get_dict())\n",
    "        page_no += 1\n",
    "        client.params_dict[\"start\"] = (page_no-1)*10 \n",
    "    \n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parse_serpapi_results(d_list):\n",
    "    meta = []\n",
    "    for d in d_list:\n",
    "        if 'error' in d:\n",
    "            print(d['error'])\n",
    "        elif d['search_metadata']['status'] == 'Success':\n",
    "            res = d['organic_results']\n",
    "            page_no = d['search_information']['page_number'] if 'page_number' in d['search_information'] else 1\n",
    "            print('Number of results on page {}: {}'.format(page_no,len(res)))\n",
    "            meta.extend([(x['title'],x['link'],x['date']) if 'date' in x\n",
    "                        else (x['title'],x['link']) for x in res])\n",
    "        else:\n",
    "            print(\"API get failure\")\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Climate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keywords to use for climate change searches\n",
    "CC_KEYWORDS = ['climate_change','global_warming','fossil_fuels','carbon_dioxide','co2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below 3 sections generate the following data structures:\n",
    "    * google_search_res_climate_change.pkl, a dictionary with outer keys for domains and inner keys for search terms;\n",
    "    * mediacloud_df.pkl, a dataframe w/ output from MediaCloud;\n",
    "    * reid_urls, a dictionary with urls from each of 6 domains searched via Google by Reid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### URLs from search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize default nested dict with outer keys for each media domain and inner keys for each keyword.\n",
    "#URLS_PER_DOMAIN = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Domains to search for climate change articles\n",
    "DOMAINS = ['www.foxnews.com','www.breitbart.com','www.theblaze.com','www.pjmedia.com','www.nationalreview.com',\n",
    "           'www.thenation.com','www.buzzfeednews.com','www.vox.com','www.washingtonpost.com','www.progressive.org',\n",
    "          'www.nytimes.com','www.motherjones.com','www.democracynow.org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching w/ query: site:www.theblaze.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 2\n",
      "Searching w/ query: site:www.theblaze.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 9\n",
      "Number of results on page 29: 1\n",
      "Searching w/ query: site:www.theblaze.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 4\n",
      "Searching w/ query: site:www.pjmedia.com climate change...\n",
      "Number of results on page 1: 2\n",
      "Searching w/ query: site:www.pjmedia.com global warming...\n",
      "Number of results on page 1: 2\n",
      "Searching w/ query: site:www.pjmedia.com fossil fuels...\n",
      "Searching w/ query: site:www.nationalreview.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 4\n",
      "Searching w/ query: site:www.nationalreview.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 8\n",
      "Searching w/ query: site:www.nationalreview.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 1\n",
      "Searching w/ query: site:www.thenation.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 5\n",
      "Searching w/ query: site:www.thenation.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 2\n",
      "Searching w/ query: site:www.thenation.com fossil fuels...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 9\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 1\n",
      "Searching w/ query: site:www.buzzfeednews.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Searching w/ query: site:www.buzzfeednews.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 2\n",
      "Searching w/ query: site:www.buzzfeednews.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 9\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 5\n",
      "Searching w/ query: site:www.vox.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Searching w/ query: site:www.vox.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 8\n",
      "Searching w/ query: site:www.vox.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 9\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Searching w/ query: site:www.washingtonpost.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Number of results on page 35: 10\n",
      "Number of results on page 36: 10\n",
      "Number of results on page 37: 10\n",
      "Number of results on page 38: 10\n",
      "Number of results on page 39: 10\n",
      "Number of results on page 40: 10\n",
      "Number of results on page 41: 10\n",
      "Number of results on page 42: 3\n",
      "Searching w/ query: site:www.washingtonpost.com global warming...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Number of results on page 35: 10\n",
      "Number of results on page 36: 10\n",
      "Number of results on page 37: 10\n",
      "Number of results on page 38: 7\n",
      "Searching w/ query: site:www.washingtonpost.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 9\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 7\n",
      "Searching w/ query: site:www.progressive.org climate change...\n",
      "Searching w/ query: site:www.progressive.org global warming...\n",
      "Searching w/ query: site:www.progressive.org fossil fuels...\n",
      "Searching w/ query: site:www.nytimes.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Number of results on page 35: 10\n",
      "Number of results on page 36: 10\n",
      "Number of results on page 37: 10\n",
      "Number of results on page 38: 10\n",
      "Number of results on page 39: 10\n",
      "Number of results on page 40: 7\n",
      "Searching w/ query: site:www.nytimes.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Number of results on page 35: 10\n",
      "Number of results on page 36: 10\n",
      "Number of results on page 37: 10\n",
      "Number of results on page 38: 10\n",
      "Number of results on page 39: 3\n",
      "Searching w/ query: site:www.nytimes.com fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 9\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 9\n",
      "Searching w/ query: site:www.motherjones.com climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 10\n",
      "Number of results on page 33: 10\n",
      "Number of results on page 34: 10\n",
      "Number of results on page 35: 10\n",
      "Number of results on page 36: 7\n",
      "Searching w/ query: site:www.motherjones.com global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 10\n",
      "Number of results on page 29: 10\n",
      "Number of results on page 30: 10\n",
      "Number of results on page 31: 10\n",
      "Number of results on page 32: 1\n",
      "Searching w/ query: site:www.motherjones.com fossil fuels...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 9\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 10\n",
      "Number of results on page 25: 10\n",
      "Number of results on page 26: 10\n",
      "Number of results on page 27: 10\n",
      "Number of results on page 28: 3\n",
      "Searching w/ query: site:www.democracynow.org climate change...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 2\n",
      "Searching w/ query: site:www.democracynow.org global warming...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 9\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 10\n",
      "Number of results on page 22: 10\n",
      "Number of results on page 23: 10\n",
      "Number of results on page 24: 6\n",
      "Searching w/ query: site:www.democracynow.org fossil fuels...\n",
      "Number of results on page 1: 10\n",
      "Number of results on page 2: 10\n",
      "Number of results on page 3: 10\n",
      "Number of results on page 4: 10\n",
      "Number of results on page 5: 10\n",
      "Number of results on page 6: 10\n",
      "Number of results on page 7: 10\n",
      "Number of results on page 8: 10\n",
      "Number of results on page 9: 10\n",
      "Number of results on page 10: 10\n",
      "Number of results on page 11: 10\n",
      "Number of results on page 12: 10\n",
      "Number of results on page 13: 10\n",
      "Number of results on page 14: 10\n",
      "Number of results on page 15: 10\n",
      "Number of results on page 16: 10\n",
      "Number of results on page 17: 10\n",
      "Number of results on page 18: 10\n",
      "Number of results on page 19: 10\n",
      "Number of results on page 20: 10\n",
      "Number of results on page 21: 9\n"
     ]
    }
   ],
   "source": [
    "# Query each domain for each keyword\n",
    "for DOMAIN in DOMAINS:\n",
    "    for KW in CC_KEYWORDS:\n",
    "        dl = do_serpapi(DOMAIN,KW)\n",
    "        results = parse_serpapi_results(dl)\n",
    "        URLS_PER_DOMAIN[DOMAIN][KW] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save nested dict\n",
    "pickle.dump(URLS_PER_DOMAIN,open('google_search_res_climate_change.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['www.foxnews.com', 'www.breitbart.com', 'www.theblaze.com', 'www.pjmedia.com', 'www.nationalreview.com', 'www.thenation.com', 'www.buzzfeednews.com', 'www.vox.com', 'www.washingtonpost.com', 'www.progressive.org', 'www.nytimes.com', 'www.motherjones.com', 'www.democracynow.org'])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLS_PER_DOMAIN.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### MediaCloud URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use the MediaCloud Python client (https://github.com/mitmedialab/MediaCloud-API-Client) to fetch stories from a larger set of media outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import mediacloud.api\n",
    "mc = mediacloud.api.MediaCloud('feb32a16d870132da7e7d93a0414d796fec95edd30a55d453075927d083a807b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These are the fields that we're interested in getting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mc_metadata = ['ap_syndicated','language','media_id','media_name','publish_date','title','guid','url','word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Read in tab-separated file with outlet id and stance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>outlet_name</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>washington_post</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>christian_science_monitor</td>\n",
       "      <td>between</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>usa_today</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "      <td>fox</td>\n",
       "      <td>anti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                outlet_name   stance\n",
       "0     1             new_york_times      pro\n",
       "1     2            washington_post      pro\n",
       "2     3  christian_science_monitor  between\n",
       "3     4                  usa_today      pro\n",
       "4  1092                        fox     anti"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_ids = pd.read_csv('mediacloud_ids.txt',sep='\\t',header=None)\n",
    "mc_ids.columns=['id','outlet_name','stance']\n",
    "mc_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fetching stories from new_york_times (outlet id = 1).\n",
      "Done fetching stories from washington_post (outlet id = 2).\n",
      "Done fetching stories from christian_science_monitor (outlet id = 3).\n"
     ]
    }
   ],
   "source": [
    "# Collect stories from each outlet\n",
    "for curr_outlet_ix in mc_ids.index:\n",
    "    curr_outlet_id = mc_ids.iloc[curr_outlet_ix]['id']\n",
    "    curr_outlet_stance = mc_ids.iloc[curr_outlet_ix]['stance']\n",
    "    fetch_size = 500\n",
    "    stories = []\n",
    "    last_processed_stories_id = 0\n",
    "    for start_year in range(2000,2021,5): # Start collecting stories from Jan. 1, 2000 \n",
    "        while len(stories) < 2000:\n",
    "            fetched_stories = mc.storyList('(climate AND chang*) OR (global AND warming) OR (carbon AND dioxide) OR (co2) AND media_id:{}'.format(curr_outlet_id), \n",
    "                                           solr_filter=mc.publish_date_query(datetime.date(start_year,1,1), datetime.date(start_year+4,12,31)),\n",
    "                                           last_processed_stories_id=last_processed_stories_id, rows= fetch_size)\n",
    "            stories.extend(fetched_stories)\n",
    "            if len( fetched_stories) < fetch_size:\n",
    "                break\n",
    "            last_processed_stories_id = stories[-1]['processed_stories_id']\n",
    "    if len(stories) > 0:\n",
    "        df = pd.DataFrame({key: [s[key] for s in stories] for key in mc_metadata})\n",
    "        df['topic'] = ['cc']*len(df)\n",
    "        df['stance'] = curr_outlet_stance\n",
    "        df.sort_values(by='publish_date')\n",
    "\n",
    "        OUTLET_NAME = df['media_name'].iloc[0].lower().replace(' ','_')\n",
    "        df.to_pickle(os.path.join('mediacloud','{}_df.pkl'.format(OUTLET_NAME)))\n",
    "        print('Done fetching stories from {} (outlet id = {}).'.format(OUTLET_NAME,curr_outlet_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, merge into a single df; filter out stories not in English; clean titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for filename in os.listdir('mediacloud'):\n",
    "    df = pd.read_pickle(os.path.join('mediacloud',filename))\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all[df_all.language == 'en']\n",
    "df_all['clean_title'] = df_all.title.apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap_syndicated</th>\n",
       "      <th>language</th>\n",
       "      <th>media_id</th>\n",
       "      <th>media_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>guid</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>topic</th>\n",
       "      <th>stance</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>18468</td>\n",
       "      <td>activistpost.com</td>\n",
       "      <td>2011-05-28 17:32:00</td>\n",
       "      <td>Activist Post: David Cameron Says Non-Violent ...</td>\n",
       "      <td>http://www.activistpost.com/2014/09/david-came...</td>\n",
       "      <td>http://www.activistpost.com/2014/09/david-came...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>anti</td>\n",
       "      <td>activist post david cameron says nonviolent co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>18468</td>\n",
       "      <td>activistpost.com</td>\n",
       "      <td>2012-09-29 05:00:00</td>\n",
       "      <td>Activist Post:  Is the CDC's Mandated Vaccine ...</td>\n",
       "      <td>http://www.activistpost.com/2012/09/is-cdcs-ma...</td>\n",
       "      <td>http://www.activistpost.com/2012/09/is-cdcs-ma...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>anti</td>\n",
       "      <td>activist post  is the cdcs mandated vaccine sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>18468</td>\n",
       "      <td>activistpost.com</td>\n",
       "      <td>2012-04-14 05:00:00</td>\n",
       "      <td>Activist Post: Haters of Humanity: The Church ...</td>\n",
       "      <td>http://www.activistpost.com/2012/04/haters-of-...</td>\n",
       "      <td>http://www.activistpost.com/2012/04/haters-of-...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>anti</td>\n",
       "      <td>activist post haters of humanity the church of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>18468</td>\n",
       "      <td>activistpost.com</td>\n",
       "      <td>2011-04-17 05:00:00</td>\n",
       "      <td>Activist Post: Masters Of The World Meet To Pl...</td>\n",
       "      <td>http://www.activistpost.com/2011/04/masters-of...</td>\n",
       "      <td>http://www.activistpost.com/2011/04/masters-of...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>anti</td>\n",
       "      <td>activist post masters of the world meet to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>18468</td>\n",
       "      <td>activistpost.com</td>\n",
       "      <td>2012-04-01 08:00:00</td>\n",
       "      <td>Is The CIA Manipulating the Weather?</td>\n",
       "      <td>https://www.activistpost.com/2016/07/is-the-ci...</td>\n",
       "      <td>https://www.activistpost.com/2016/07/is-the-ci...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>anti</td>\n",
       "      <td>is the cia manipulating the weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10442</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2020-02-23 19:53:13</td>\n",
       "      <td>The anti-Greta: A conservative think tank take...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>pro</td>\n",
       "      <td>the antigreta a conservative think tank takes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10443</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2020-03-06 12:00:00</td>\n",
       "      <td>It was only a matter of time. Lab-created mol...</td>\n",
       "      <td>https://www.washingtonpost.com/lifestyle/food/...</td>\n",
       "      <td>https://www.washingtonpost.com/lifestyle/food/...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>pro</td>\n",
       "      <td>it was only a matter of time labcreated molecu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10444</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2020-03-06 03:27:58</td>\n",
       "      <td>Global crises have spurred declines in emissio...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>pro</td>\n",
       "      <td>global crises have spurred declines in emissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10445</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2020-03-09 07:56:07</td>\n",
       "      <td>The Energy 202: Three charts that explain what...</td>\n",
       "      <td>https://www.washingtonpost.com/politics/the-en...</td>\n",
       "      <td>https://www.washingtonpost.com/politics/the-en...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>pro</td>\n",
       "      <td>the energy 202 three charts that explain what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10446</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2020-03-13 14:32:02</td>\n",
       "      <td>Pollution is plummeting in Italy in the wake o...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>https://www.washingtonpost.com/climate-environ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc</td>\n",
       "      <td>pro</td>\n",
       "      <td>pollution is plummeting in italy in the wake o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10305 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ap_syndicated language  media_id        media_name  \\\n",
       "0              False       en     18468  activistpost.com   \n",
       "1              False       en     18468  activistpost.com   \n",
       "2              False       en     18468  activistpost.com   \n",
       "3              False       en     18468  activistpost.com   \n",
       "4              False       en     18468  activistpost.com   \n",
       "...              ...      ...       ...               ...   \n",
       "10442          False       en         2   Washington Post   \n",
       "10443          False       en         2   Washington Post   \n",
       "10444          False       en         2   Washington Post   \n",
       "10445          False       en         2   Washington Post   \n",
       "10446          False       en         2   Washington Post   \n",
       "\n",
       "              publish_date                                              title  \\\n",
       "0      2011-05-28 17:32:00  Activist Post: David Cameron Says Non-Violent ...   \n",
       "1      2012-09-29 05:00:00  Activist Post:  Is the CDC's Mandated Vaccine ...   \n",
       "2      2012-04-14 05:00:00  Activist Post: Haters of Humanity: The Church ...   \n",
       "3      2011-04-17 05:00:00  Activist Post: Masters Of The World Meet To Pl...   \n",
       "4      2012-04-01 08:00:00               Is The CIA Manipulating the Weather?   \n",
       "...                    ...                                                ...   \n",
       "10442  2020-02-23 19:53:13  The anti-Greta: A conservative think tank take...   \n",
       "10443  2020-03-06 12:00:00  It was only a matter of time. Lab-created mol...   \n",
       "10444  2020-03-06 03:27:58  Global crises have spurred declines in emissio...   \n",
       "10445  2020-03-09 07:56:07  The Energy 202: Three charts that explain what...   \n",
       "10446  2020-03-13 14:32:02  Pollution is plummeting in Italy in the wake o...   \n",
       "\n",
       "                                                    guid  \\\n",
       "0      http://www.activistpost.com/2014/09/david-came...   \n",
       "1      http://www.activistpost.com/2012/09/is-cdcs-ma...   \n",
       "2      http://www.activistpost.com/2012/04/haters-of-...   \n",
       "3      http://www.activistpost.com/2011/04/masters-of...   \n",
       "4      https://www.activistpost.com/2016/07/is-the-ci...   \n",
       "...                                                  ...   \n",
       "10442  https://www.washingtonpost.com/climate-environ...   \n",
       "10443  https://www.washingtonpost.com/lifestyle/food/...   \n",
       "10444  https://www.washingtonpost.com/climate-environ...   \n",
       "10445  https://www.washingtonpost.com/politics/the-en...   \n",
       "10446  https://www.washingtonpost.com/climate-environ...   \n",
       "\n",
       "                                                     url word_count topic  \\\n",
       "0      http://www.activistpost.com/2014/09/david-came...       None    cc   \n",
       "1      http://www.activistpost.com/2012/09/is-cdcs-ma...       None    cc   \n",
       "2      http://www.activistpost.com/2012/04/haters-of-...       None    cc   \n",
       "3      http://www.activistpost.com/2011/04/masters-of...       None    cc   \n",
       "4      https://www.activistpost.com/2016/07/is-the-ci...       None    cc   \n",
       "...                                                  ...        ...   ...   \n",
       "10442  https://www.washingtonpost.com/climate-environ...       None    cc   \n",
       "10443  https://www.washingtonpost.com/lifestyle/food/...       None    cc   \n",
       "10444  https://www.washingtonpost.com/climate-environ...       None    cc   \n",
       "10445  https://www.washingtonpost.com/politics/the-en...       None    cc   \n",
       "10446  https://www.washingtonpost.com/climate-environ...       None    cc   \n",
       "\n",
       "      stance                                        clean_title  \n",
       "0       anti  activist post david cameron says nonviolent co...  \n",
       "1       anti  activist post  is the cdcs mandated vaccine sc...  \n",
       "2       anti  activist post haters of humanity the church of...  \n",
       "3       anti  activist post masters of the world meet to pla...  \n",
       "4       anti                is the cia manipulating the weather  \n",
       "...      ...                                                ...  \n",
       "10442    pro  the antigreta a conservative think tank takes ...  \n",
       "10443    pro  it was only a matter of time labcreated molecu...  \n",
       "10444    pro  global crises have spurred declines in emissio...  \n",
       "10445    pro  the energy 202 three charts that explain what ...  \n",
       "10446    pro  pollution is plummeting in italy in the wake o...  \n",
       "\n",
       "[10305 rows x 12 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3407, 12)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all.stance=='anti'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6428, 12)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all.stance=='pro'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_all.to_pickle('mediacloud_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Reid URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reid_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_dir = '/Users/yiweiluo/Dropbox/research/QP2/reid_urls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(load_dir):\n",
    "    domain = '_'.join(filename.split('_')[:-1])\n",
    "    urls = pd.read_csv(load_dir+filename,header=None)\n",
    "    reid_urls[domain] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['buzzfeed_news', 'democracy_now', 'the_nation', 'the_progressive', 'vox', 'washington_post'])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reid_urls.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(reid_urls,open('reid_urls.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section will create a file ```temp_vax_blog_urls.pkl``` containing urls from each blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "advocacy_blogs = ['https://www.voicesforvaccines.org/blog/',\n",
    "                 'https://adultvaccinesnow.org/blog/',\n",
    "                 'https://shotofprevention.com/',\n",
    "                 'https://immunizationevidence.org/featured_issues/',\n",
    "                 'https://www.nfid.org/blog/',\n",
    "                 'https://vaxopedia.org/category/blog/',\n",
    "                 'https://www.familiesfightingflu.org/insights-on-influenza/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create datastructure to store post urls from each blog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#blog_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Anti-vaccine blogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get URLs from each blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Children's Health Defense\n",
    "root_url = 'https://childrenshealthdefense.org/kennedy-news-views/page/'\n",
    "for p_no in range(1,17):\n",
    "    url = root_url + str(p_no)\n",
    "    soup = soupify(url)\n",
    "    articles = soup.find_all('section',attrs={\"class\":'knv-section'})\n",
    "    urls_and_meta = []\n",
    "    for art in articles:\n",
    "        art_meta = art.find('figcaption').find('h4').find('a')\n",
    "        art_date = art.find('figcaption').find('span').text.strip()\n",
    "        art_title = art_meta.text.strip()\n",
    "        art_url = art_meta['href']\n",
    "        urls_and_meta.append((art_url,art_title,art_date))\n",
    "    blog_dict['CHD'].extend(urls_and_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Vaccine Safety Commission\n",
    "root_url = 'https://vaccinesafetycommission.org/studies.html'\n",
    "soup = soupify(root_url)\n",
    "panel_bodies = soup.find_all('div',attrs={'class':'panel-body'})\n",
    "print(len(panel_bodies))\n",
    "text = \"\"\n",
    "for pb in panel_bodies:\n",
    "    text += pb.text.strip()\n",
    "blog_dict['vax_safety_commission'].append((root_url,'50 Studies the AAP Avoided to Mention',None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Vaccine-advocacy blogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get URLs from each blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Voices for Vaccines\n",
    "for page_no in range(1,21):\n",
    "    url = 'https://www.voicesforvaccines.org/blog/page/{}/'.format(page_no)\n",
    "    soup = soupify(url)\n",
    "    posts = soup.find('div',attrs={'class':'collection posts view-as-grid two-thirds'})\n",
    "    ul = posts.find_all('ul',recursive=False)\n",
    "    assert len(ul) == 1\n",
    "    lis = ul[0].find_all('article')\n",
    "    articles = [x.find('h3').find('a') for x in lis]\n",
    "    urls_and_meta = [(x['href'],x['title']) for x in articles]\n",
    "    blog_dict['https://www.voicesforvaccines.org/blog/'].extend(urls_and_meta)\n",
    "    \n",
    "# Adult Vaccine Access Coalition\n",
    "for page_no in range(1,5):\n",
    "    url = 'https://adultvaccinesnow.org/blog/page/{}/'.format(page_no)\n",
    "    soup = soupify(url)\n",
    "    main = soup.find('div',attrs={'class':'x-main full'})\n",
    "    arts = main.find_all('article')\n",
    "    art_objs = [a.find('h2',attrs={'class':True}).find('a') for a in arts]\n",
    "    urls_and_titles = [(x['href'],x.text) for x in art_objs]\n",
    "    dates = [parser.parse(a.find('header',attrs={'class':'entry-header'}).find('span').text)\n",
    "         for a in arts]\n",
    "    urls_and_meta = [(x[0],x[1],dates[ix]) for ix,x in enumerate(urls_and_titles)]\n",
    "    blog_dict['https://adultvaccinesnow.org/blog/'].extend(urls_and_meta)\n",
    "    \n",
    "# Shot of Prevention\n",
    "n_per_cat = {'science-research':22, \n",
    "            'testimonials-personal-stories':19,\n",
    "            'questions':12,\n",
    "            'policy-advocacy':27,\n",
    "            'expert-insights-and-commentary':32,\n",
    "            'news-outbreaks':27}\n",
    "\n",
    "for category in ['news-outbreaks','science-research','expert-insights-and-commentary',\n",
    "                'policy-advocacy','questions','testimonials-personal-stories']:\n",
    "    for page_no in range(1,n_per_cat[category]+1):\n",
    "        url = 'https://shotofprevention.com/category/{}/page/{}/'.format(category,page_no)\n",
    "        soup = soupify(url)\n",
    "        container = soup.find('div',attrs={'class':'category-container'})\n",
    "        art_objs = container.find_all('div',attrs={'class':'single-box'})\n",
    "        articles = [a.find('h3') for a in art_objs]\n",
    "        urls_and_meta = [(x.find('a')['href'],x.text) for x in articles]\n",
    "        blog_dict['https://shotofprevention.com/'].extend(urls_and_meta)\n",
    "        \n",
    "# VoICE https://immunizationevidence.org\n",
    "for page_no in range(1,3):\n",
    "    url = 'https://immunizationevidence.org/featured_issues/page/{}/'.format(page_no)\n",
    "    soup = soupify(url)\n",
    "    issues = soup.find_all('div',attrs={'class','featuredIssueHighlights'})\n",
    "    titles = [x.find('h3',attrs={'class':'featuredTitle'}).text for x in issues]\n",
    "    urls = [x.find('a',attrs={'class':'blueButton'})['href'] for x in issues]\n",
    "    urls_and_meta = list(zip(urls,titles))\n",
    "    blog_dict['https://immunizationevidence.org/featured_issues/'].extend(urls_and_meta)\n",
    "    \n",
    "# National Foundation for Infectious Diseases https://www.nfid.org/blog/\n",
    "for page_no in range(1,3):\n",
    "    url = 'https://www.nfid.org/blog/page/{}/'.format(page_no)\n",
    "    soup = soupify(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(blog_dict,open('temp_vax_blog_urls.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.voicesforvaccines.org/blog/ 193\n",
      "https://adultvaccinesnow.org/blog/ 40\n",
      "https://shotofprevention.com/ 1365\n",
      "https://immunizationevidence.org/featured_issues/ 13\n",
      "CHD 469\n",
      "vax_safety_commission 1\n"
     ]
    }
   ],
   "source": [
    "test = pickle.load(open('temp_vax_blog_urls.pkl','rb'))\n",
    "for k in test:\n",
    "    print(k,len(test[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_cc_urls = pickle.load(open('google_search_res_climate_change.pkl','rb')) # domain, keyword, title, url, date\n",
    "mediacloud_cc_urls = pd.read_pickle('mediacloud_df.pkl') # ap_syndicated, domain, title, url, date\n",
    "reid_cc_urls = pd.read_pickle('reid_urls.pkl') # url only\n",
    "vax_urls = pickle.load(open('temp_vax_blog_urls.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_google_res_stance(x):\n",
    "    if 'foxnews.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'breitbart.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'blaze.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'pjmedia.com' in x:\n",
    "        return 'anti'\n",
    "    elif 'nationalreview.com' in x:\n",
    "        return 'anti'\n",
    "    else:\n",
    "        return 'pro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out non-(relevant)-article URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are NYT tags that we deem indicate that an article is irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "NYT_SECTIONS_TO_REMOVE = set(['/automobiles/','/autoreviews/','/autoshow/','/business/','/campaign-stops/',\n",
    "                          '/crosswords/',\n",
    "               '/booming/','/giving/','/gmcvb/','/jobs/','/lens/','/letters/','/newyorktoday/',\n",
    "               '/nutrition/','/sept-11-reckoning/','/smallbusiness/',\n",
    "               '/sunday-review/','/garden/','/arts/','/theater/','/sports/','/dining/','/books/','/weekinreview/','/your-money/',\n",
    "                         '/movies/','/fashion/','/technology/','/pageoneplus/','/travel/','/nytnow/',\n",
    "                         '/public-editor/','/education/','/learning/','/podcasts/','/style/','/t-magazine/',\n",
    "                         '/reader-center/','/awardsseason/','/briefing/','/dealbook/','/es/',\n",
    "                          '/greathomesanddestinations/','/interactive/','/media/',\n",
    "                         '/mutfund/','/obituaries/','/personaltech/','/realestate/',\n",
    "                          '/smarter-living/','/todayspaper/','/your-money/','/yourtaxes/',\n",
    "                             '/slideshow/','/interactive/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following are URL tags that indicate a given URL is not truly a text article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_URL_STRS = set(['/tag/','/author/','/clips/','/podcasts/','/subject/','/authors/',\n",
    "                         '/category/','/person/','/category/','/shows/','/video/','/topic/',\n",
    "                         '/es/','/topics/','/de/','/tags/','/slideshow/',\n",
    "                         '/interactive/','/transcripts/','/headlines/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_URL_INIT_STRS = set(['rss.','feeds.','rssfeeds.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rss(url):\n",
    "    for xx in BLACKLIST_URL_INIT_STRS:\n",
    "        if url[:len(xx)] == xx:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blacklist(url):\n",
    "    for xx in BLACKLIST_URL_STRS:\n",
    "        if xx in url:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not is_blacklist(combined_df.url.loc[4539]) and \\\n",
    "not is_rss(combined_df.url.loc[4539])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe combining all data structures with urls, that filters according to above criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# url, title, date, domain, is_AP\n",
    "filtered_urls = []\n",
    "filtered_titles = []\n",
    "filtered_dates = []\n",
    "filtered_domains = []\n",
    "filtered_stances = []\n",
    "filtered_topics = []\n",
    "filtered_is_AP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for key in google_cc_urls:\n",
    "    for keyword in google_cc_urls[key]:\n",
    "        for item in google_cc_urls[key][keyword]:\n",
    "            url = item[1]\n",
    "            if not is_rss(url) and not is_blacklist(url):\n",
    "                title = item[0]\n",
    "                date = item[2] if len(item) > 2 else None\n",
    "                stance = get_google_res_stance(url)\n",
    "                topic = 'cc'\n",
    "                is_AP = None\n",
    "\n",
    "                if ' | ' not in title:\n",
    "                    filtered_urls.append(url)\n",
    "                    filtered_titles.append(title)\n",
    "                    filtered_dates.append(date)\n",
    "                    filtered_domains.append(key)\n",
    "                    filtered_stances.append(stance)\n",
    "                    filtered_topics.append(topic)\n",
    "                    filtered_is_AP.append(is_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for ix in mediacloud_cc_urls.index:\n",
    "    row = mediacloud_cc_urls.loc[ix]\n",
    "    url = row['url'] if 'http' in row['url'] else row['guid']\n",
    "    if not is_rss(url) and not is_blacklist(url):\n",
    "        title = row['clean_title']\n",
    "        date = row['publish_date']\n",
    "        domain = row['media_name']\n",
    "        stance = row['stance']\n",
    "        topic = row['topic']\n",
    "        is_AP = row['ap_syndicated']\n",
    "\n",
    "        if ' | ' not in title:\n",
    "            filtered_urls.append(url)\n",
    "            filtered_titles.append(title)\n",
    "            filtered_dates.append(date)\n",
    "            filtered_domains.append(domain)\n",
    "            filtered_stances.append(stance)\n",
    "            filtered_topics.append(topic)\n",
    "            filtered_is_AP.append(is_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for key in reid_cc_urls:\n",
    "    for url in reid_cc_urls[key][0].values:\n",
    "        if not is_rss(url) and not is_blacklist(url):\n",
    "            filtered_urls.append(url)\n",
    "            filtered_titles.append(None)\n",
    "            filtered_dates.append(None)\n",
    "            filtered_domains.append(key)\n",
    "            filtered_stances.append('pro')\n",
    "            filtered_topics.append('cc')\n",
    "            filtered_is_AP.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for key in vax_urls:\n",
    "    for item in vax_urls[key]:\n",
    "        url = item[0]\n",
    "        if not is_blacklist(url) and not is_rss(url):\n",
    "            title = item[1]\n",
    "            item[2] if len(item) > 2 else None\n",
    "            stance = 'anti' if key == 'CHD' or key == 'vax_safety_commission' else 'pro'\n",
    "            is_AP = False\n",
    "        \n",
    "            filtered_urls.append(url)\n",
    "            filtered_titles.append(title)\n",
    "            filtered_dates.append(date)\n",
    "            filtered_domains.append(key)\n",
    "            filtered_stances.append(stance)\n",
    "            filtered_topics.append('vax')\n",
    "            filtered_is_AP.append(is_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame({'url':filtered_urls,\n",
    "                              'title':filtered_titles,\n",
    "                              'date':filtered_dates,\n",
    "                              'domain':filtered_domains,\n",
    "                              'stance':filtered_stances,\n",
    "                              'topic':filtered_topics,\n",
    "                              'is_AP':filtered_is_AP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26977, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.foxnews.com/science/todays-climate...</td>\n",
       "      <td>Today's Climate Change Is Worse Than Anything ...</td>\n",
       "      <td>Jul 25, 2019</td>\n",
       "      <td>www.foxnews.com</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.foxnews.com/science/climate-change...</td>\n",
       "      <td>Climate change could destroy half of Earth's a...</td>\n",
       "      <td>Feb 13, 2020</td>\n",
       "      <td>www.foxnews.com</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.foxnews.com/media/david-webb-clima...</td>\n",
       "      <td>David Webb: 'Climate change is the religion of...</td>\n",
       "      <td>Sep 24, 2019</td>\n",
       "      <td>www.foxnews.com</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.foxnews.com/science/half-worlds-be...</td>\n",
       "      <td>Half of world's beaches will disappear by 2100...</td>\n",
       "      <td>Mar 2, 2020</td>\n",
       "      <td>www.foxnews.com</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.foxnews.com/media/mattis-climate-s...</td>\n",
       "      <td>Mattis turns up heat on climate change deniers...</td>\n",
       "      <td>Sep 5, 2019</td>\n",
       "      <td>www.foxnews.com</td>\n",
       "      <td>anti</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.foxnews.com/science/todays-climate...   \n",
       "1  https://www.foxnews.com/science/climate-change...   \n",
       "2  https://www.foxnews.com/media/david-webb-clima...   \n",
       "3  https://www.foxnews.com/science/half-worlds-be...   \n",
       "4  https://www.foxnews.com/media/mattis-climate-s...   \n",
       "\n",
       "                                               title          date  \\\n",
       "0  Today's Climate Change Is Worse Than Anything ...  Jul 25, 2019   \n",
       "1  Climate change could destroy half of Earth's a...  Feb 13, 2020   \n",
       "2  David Webb: 'Climate change is the religion of...  Sep 24, 2019   \n",
       "3  Half of world's beaches will disappear by 2100...   Mar 2, 2020   \n",
       "4  Mattis turns up heat on climate change deniers...   Sep 5, 2019   \n",
       "\n",
       "            domain stance topic is_AP  \n",
       "0  www.foxnews.com   anti    cc  None  \n",
       "1  www.foxnews.com   anti    cc  None  \n",
       "2  www.foxnews.com   anti    cc  None  \n",
       "3  www.foxnews.com   anti    cc  None  \n",
       "4  www.foxnews.com   anti    cc  None  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a standardization function on the ``domain`` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def standardize_domain(x):\n",
    "    if x == 'Guardian US':\n",
    "        return 'guardian_us'\n",
    "    elif 'washingtonpost.com' in x:\n",
    "        return 'wapo'\n",
    "    elif 'vox.com' in x:\n",
    "        return 'vox'\n",
    "    elif 'breitbart.com' in x:\n",
    "        return 'breitbart'\n",
    "    elif 'nytimes.com' in x:\n",
    "        return 'nyt'\n",
    "    elif 'motherjones.com' in x:\n",
    "        return 'mj'\n",
    "    elif x == 'democracy_now':\n",
    "        return 'dem_now'\n",
    "    elif 'foxnews.com' in x:\n",
    "        return 'fox'\n",
    "    elif 'buzzfeednews.com' in x:\n",
    "        return 'buzzfeed'\n",
    "    elif x == 'Daily Caller':\n",
    "        return 'daily_caller'\n",
    "    elif x == 'Washington Post':\n",
    "        return 'wapo'\n",
    "    elif 'theblaze.com' in x:\n",
    "        return 'blaze'\n",
    "    elif 'democracynow.org' in x:\n",
    "        return 'dem_now'\n",
    "    elif x == 'Grist':\n",
    "        return 'grist'\n",
    "    elif x == 'New York Times':\n",
    "        return 'nyt'\n",
    "    elif 'nationalreview.com' in x:\n",
    "        return 'nat_review'\n",
    "    elif 'thenation.com' in x:\n",
    "        return 'nation'\n",
    "    elif x == 'Breitbart':\n",
    "        return 'breitbart'\n",
    "    elif x == 'Christian Science Monitor':\n",
    "        return 'cs_monitor'\n",
    "    elif x == 'buzzfeed_news':\n",
    "        return 'buzzfeed'\n",
    "    elif x == 'washington_post':\n",
    "        return 'wapo'\n",
    "    elif x == 'FOX News':\n",
    "        return 'fox'\n",
    "    elif x == 'USA Today':\n",
    "        return 'usa_today'\n",
    "    elif x == 'Mother Jones':\n",
    "        return 'mj'\n",
    "    elif x == 'NBC News':\n",
    "        return 'nbc'\n",
    "    elif x == 'Democracy Now!':\n",
    "        return 'dem_now'\n",
    "    elif x == 'National Review':\n",
    "        return 'nat_review'\n",
    "    elif x == 'CNS News':\n",
    "        return 'cns'\n",
    "    elif x == 'Buzzfeed':\n",
    "        return 'buzzfeed'\n",
    "    elif x == 'The Nation':\n",
    "        return 'nation'\n",
    "    elif 'pjmedia.com' in x:\n",
    "        return 'pj'\n",
    "    elif 'pajamas_media' in x:\n",
    "        return 'pj'\n",
    "    else:\n",
    "        return x.lower().strip().replace(' ','_').replace('.com','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['domain'] = combined_df.domain.apply(standardize_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wapo                     2763\n",
       "vox                      2122\n",
       "breitbart                1918\n",
       "nyt                      1912\n",
       "guardian_us              1863\n",
       "                         ... \n",
       "pj                          4\n",
       "charismanews                3\n",
       "cbn                         3\n",
       "conservative_review         2\n",
       "vax_safety_commission       1\n",
       "Name: domain, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we strip extra whitespace around titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.title = combined_df.title.apply(lambda x: x.strip() if x \n",
    "                                           is not None else x)\n",
    "#combined_df.to_pickle('temp_combined_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we remove initial 'http(s):' from urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_url(x):\n",
    "    return x.split('http://')[-1].split('https://')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.url = combined_df.url.apply(strip_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=26977, step=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26977, 7)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we sort ```combined_df``` by ```title``` and ```date``` so that when we drop duplicate URLs, we keep the one that doesn't have a null value for these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26977, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.sort_values(['title','date'],axis=0)#,ignore_index=True)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21469, 7)\n"
     ]
    }
   ],
   "source": [
    "combined_df = combined_df.drop_duplicates(subset='url',keep='first')#,ignore_index=True)\n",
    "print(combined_df.shape)\n",
    "combined_df.to_pickle('temp_combined_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping fulltext and missing meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21469, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_pickle('temp_combined_df.pkl')\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use newspaper3k (https://newspaper.readthedocs.io/en/latest/) to scrape article information including fulltext and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from newspaper import ArticleException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper functions for using newspaper3k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def newspaper_parse(url):\n",
    "    if url[:8] != 'https://':\n",
    "        url = 'https://'+url\n",
    "        \n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return (article.title,\n",
    "                article.text.replace('\\n',' '))\n",
    "    except ArticleException:\n",
    "        return (None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     2,
     4,
     7,
     10,
     13,
     16,
     19,
     21,
     23,
     25,
     28,
     31,
     34,
     37,
     40,
     43,
     45,
     47,
     50,
     53,
     56,
     59,
     61,
     68
    ]
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def get_fulltext(url,domain):\n",
    "    stop_ix,title,text = None,None,None\n",
    "    if domain == 'alternet':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'american_conservative':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'https://adultvaccinesnow.org/blog/':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'activistpost':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -4\n",
    "    elif domain == 'american_thinker':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'blaze':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'boston_globe':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'breitbart':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'buzzfeed':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'cbn':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'charismanews':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -14\n",
    "    elif domain == 'chd':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'cns':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'commdiginews':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'conservative_review':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'conservative_treehouse':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'conservativedailynews':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -4\n",
    "    elif domain == 'conservativefiringline':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -10\n",
    "    elif domain == 'cs_monitor':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'daily_caller':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -3\n",
    "    elif domain == 'daily_dot':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'dem_now':\n",
    "        soup = soupify(url)\n",
    "        try:\n",
    "            ps = soup.find('div',attrs={'itemprop':'articleBody'}).find_all('p')\n",
    "        except AttributeError:\n",
    "            ps = soup.find('div',attrs={'class':'story_summary'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "    elif domain == 'drudgereport':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'fox':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'gateway_pundit':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'gawker':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'grabien':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'grist':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'guardian_us':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'hot_air':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'https://adultvaccinesnow.org/blog/':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'https://immunizationevidence.org/featured_issues/':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'https://shotofprevention/':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'https://www.voicesforvaccines.org/blog/':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'independentsentinel':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'infowars':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'inthesetimes':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'libertyunyielding':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'mj':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'nat_review':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'nation':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'nbc':\n",
    "        soup = soupify(url)\n",
    "        ps = soup.find('div',attrs={'class':'article-body__content'}).\\\n",
    "        find_all('p',attrs={'class':'endmarkEnabled'})\n",
    "        text = ' '.join([p.text.replace('\\n',' ') for p in ps])\n",
    "    elif domain == 'new_york_magazine':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'newsweek':\n",
    "        soup = soupify(url)\n",
    "        ps = soup.find('div',attrs={'class':'article-content'}).find_all('p')\n",
    "        text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "    elif domain == 'newswithviews':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -10\n",
    "    elif domain == 'nyt':\n",
    "        try:\n",
    "            soup = soupify(url)\n",
    "            if soup is not None:\n",
    "                ps = soup.find('section',attrs={'itemprop':'articleBody'}).find_all('p')#,recursive=False)\n",
    "                text = ' '.join([p.text.replace('\\n', ' ') for p in ps])\n",
    "                stop_ix = -5\n",
    "        except HTTPError:\n",
    "            pass\n",
    "    elif domain == 'pajamas_media':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'pj':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'progressivestoday':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'quartz':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'rare.us':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'reason':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -3\n",
    "    elif domain == 'redstate':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'sgtreport':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'shoebat':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'sonsoflibertymedia':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = -1\n",
    "    elif domain == 'the_american_conservative':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'the_american_spectator':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'the_nation':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'the_progressive':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'the_verge':\n",
    "        title,text = newspaper_parse(url)\n",
    "        stop_ix = 0\n",
    "    elif domain == 'the_week':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'usa_today':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'vax_safety_commission':\n",
    "        root_url = 'https://vaccinesafetycommission.org/studies.html'\n",
    "        soup = soupify(root_url)\n",
    "        panel_bodies = soup.find_all('div',attrs={'class':'panel-body'})\n",
    "        #print(len(panel_bodies))\n",
    "        text = \"\"\n",
    "        for pb in panel_bodies:\n",
    "            text += pb.text.strip()\n",
    "    elif domain == 'vice':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'vox':\n",
    "        title,text = newspaper_parse(url)\n",
    "    elif domain == 'wapo':\n",
    "        title,text = newspaper_parse(url)\n",
    "    else:\n",
    "        print('Unknown domain!')\n",
    "    \n",
    "    if text is not None and len(text) > 0:\n",
    "        text = text.strip()\n",
    "        sent_tokens = sent_tokenize(text)\n",
    "    \n",
    "        # Remove final 2 sentences (usually about social media)\n",
    "        sent_tokens = sent_tokens[:stop_ix] if stop_ix is not None else sent_tokens[:-2]\n",
    "        text = ' '.join(sent_tokens)\n",
    "    \n",
    "    return (title,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go through every article and scrape its fulltext. If its title is null, or shorter than the title that Newspaper finds, we replace that field with the Newspaper title.<br>\n",
    "We define a special separator token, ```SEP_TOK```, to use to replace the \"/\" character in the urls to identify each article uniquely, and add this unique key to ```combined_df```. We then save the fulltext in a directory called \"fulltexts\" which has a .txt file named with each unique key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOK = '[SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls_needed = []\n",
    "#url_unique_keys = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "Unknown domain!\n",
      "10200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 703. Skipping tag 59932\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1727. Skipping tag 59932\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 534. Skipping tag 59932\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1558. Skipping tag 59932\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 33434\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 33437\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 36867\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37378\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37380\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37381\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37382\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37386\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "Unknown domain!\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "Unknown domain!\n",
      "Unknown domain!\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n"
     ]
    }
   ],
   "source": [
    "for n,ix in enumerate(combined_df.index):\n",
    "    row = combined_df.loc[ix]\n",
    "    url = row['url']\n",
    "    domain = row['domain']\n",
    "    title = row['title']\n",
    "    try:\n",
    "        newspaper_title,ft = get_fulltext(url,domain)\n",
    "    \n",
    "        # Replace title w/ newspaper title if it's longer \n",
    "        if newspaper_title is not None and \\\n",
    "        title is not None and \\\n",
    "        len(newspaper_title) > len(title):\n",
    "            title = newspaper_title\n",
    "        # Replace title w/ newspaper title if the former is null but\n",
    "        # not the latter\n",
    "        elif newspaper_title is not None and title is None:\n",
    "            title = newspaper_title\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if ft is not None:\n",
    "            save_url = SEP_TOK.join(url.split('/'))\n",
    "            try:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url\n",
    "            except OSError:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url[:90]),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url[:90]\n",
    "        else:\n",
    "            urls_needed.append(ix)\n",
    "    except AttributeError:\n",
    "        urls_needed.append(ix)\n",
    "        \n",
    "    if n % 100 == 0:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_unique_keys))\n",
    "pickle.dump(url_unique_keys,open('url_2_unique_key.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8004\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(urls_needed,open('fulltext_needed_urls.pkl','wb'))\n",
    "#urls_needed = pickle.load(open('./temp/fulltext_needed_urls.pkl','rb'))\n",
    "print(len(urls_needed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ix in urls_needed:\n",
    "    assert combined_df.loc[ix].shape == (7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_df = combined_df.loc[urls_needed]\n",
    "#missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "Unknown domain!\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "Unknown domain!\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "Unknown domain!\n",
      "Unknown domain!\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "#urls_needed_2 = []\n",
    "for n,ix in enumerate(missing_df.index):\n",
    "    row = missing_df.loc[ix]\n",
    "    url = row['url']\n",
    "    domain = row['domain']\n",
    "    title = row['title']\n",
    "    try:\n",
    "        newspaper_title,ft = get_fulltext(url,domain)\n",
    "    \n",
    "        # Replace title w/ newspaper title if it's longer \n",
    "        if newspaper_title is not None and \\\n",
    "        title is not None and \\\n",
    "        len(newspaper_title) > len(title):\n",
    "            title = newspaper_title\n",
    "        # Replace title w/ newspaper title if the former is null but\n",
    "        # not the latter\n",
    "        elif newspaper_title is not None and title is None:\n",
    "            title = newspaper_title\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if ft is not None:\n",
    "            save_url = SEP_TOK.join(url.split('/'))\n",
    "            try:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url\n",
    "            except OSError:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url[:90]),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url[:90]\n",
    "        else:\n",
    "            urls_needed_2.append(ix)\n",
    "    except AttributeError:\n",
    "        urls_needed_2.append(ix)\n",
    "        \n",
    "    if n % 100 == 0:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20585\n"
     ]
    }
   ],
   "source": [
    "print(len(url_unique_keys))\n",
    "pickle.dump(url_unique_keys,open('url_2_unique_key.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump(urls_needed_2,open('fulltext_needed_urls_2.pkl','wb'))\n",
    "urls_needed_2 = pickle.load(open('fulltext_needed_urls_2.pkl','rb'))\n",
    "url_unique_keys = pickle.load(open('url_2_unique_key.pkl','rb'))\n",
    "print(len(urls_needed_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_needed_2_sans_rss = []\n",
    "for ix in urls_needed_2:\n",
    "    if ix in combined_df.index:\n",
    "        row = combined_df.loc[ix]\n",
    "        if not is_rss(row.url) and '/headlines/' not in row.url:\n",
    "            urls_needed_2_sans_rss.append(ix)\n",
    "len(urls_needed_2_sans_rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_df = combined_df.loc[urls_needed_2_sans_rss]\n",
    "#missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "#vurls_needed_3 = []\n",
    "for n,ix in enumerate(missing_df.index):\n",
    "    row = missing_df.loc[ix]\n",
    "    url = row['url']\n",
    "    domain = row['domain']\n",
    "    title = row['title']\n",
    "    try:\n",
    "        newspaper_title,ft = get_fulltext(url,domain)\n",
    "    \n",
    "        # Replace title w/ newspaper title if it's longer \n",
    "        if newspaper_title is not None and \\\n",
    "        title is not None and \\\n",
    "        len(newspaper_title) > len(title):\n",
    "            title = newspaper_title\n",
    "        # Replace title w/ newspaper title if the former is null but\n",
    "        # not the latter\n",
    "        elif newspaper_title is not None and title is None:\n",
    "            title = newspaper_title\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if ft is not None:\n",
    "            save_url = SEP_TOK.join(url.split('/'))\n",
    "            try:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url\n",
    "            except OSError:\n",
    "                with open('./fulltexts/{}.txt'.format(save_url[:90]),'w') as f:\n",
    "                    f.write(ft)\n",
    "                url_unique_keys[url] = save_url[:90]\n",
    "        else:\n",
    "            urls_needed_3.append(ix)\n",
    "    except AttributeError:\n",
    "        urls_needed_3.append(ix)\n",
    "        \n",
    "    if n % 100 == 0:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20588\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(urls_needed_3,open('fulltext_needed_urls_3.pkl','wb'))\n",
    "pickle.dump(url_unique_keys,open('url_2_unique_key.pkl','wb'))\n",
    "#urls_needed_2 = pickle.load(open('fulltext_needed_urls_2.pkl','rb'))\n",
    "#url_unique_keys = pickle.load(open('url_2_unique_key.pkl','rb'))\n",
    "print(len(url_unique_keys))\n",
    "print(len(urls_needed_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = combined_df.loc[urls_needed_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyt              194\n",
       "wapo              27\n",
       "pajamas_media     19\n",
       "fox               10\n",
       "blaze              7\n",
       "nbc                4\n",
       "newsweek           3\n",
       "nat_review         1\n",
       "cns                1\n",
       "alternet           1\n",
       "guardian_us        1\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out URLs that don't have article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580\n",
      "20580\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counted_fnames = Counter(os.listdir('fulltexts'))\n",
    "print(len(os.listdir('fulltexts')))\n",
    "print(len(counted_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "fulltext_dir='./fulltexts/'\n",
    "fnames = set(os.listdir(fulltext_dir))\n",
    "\n",
    "def get_fulltext(url,fulltext_dir='./fulltexts/'):\n",
    "    fname = url.replace('/','[SEP]')\n",
    "    if fname+'.txt' in fnames or fname[:90]+'.txt' in fnames:\n",
    "        try:\n",
    "            with open(fulltext_dir+fname+'.txt','r') as f:\n",
    "                lines = f.readlines()\n",
    "        except OSError:\n",
    "            with open(fulltext_dir+fname[:90]+'.txt','r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "        return lines\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls_ft_df = [u for u in combined_df.url.values if\n",
    "             len(get_fulltext(u)) > 0]\n",
    "urls_ft_df = set(urls_ft_df)\n",
    "len(urls_ft_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16477, 7)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_ft = combined_df.loc[combined_df.url.isin(urls_ft_df)]\n",
    "combined_df_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.buzzfeednews.com/article/tasneemnashrulla/eat-babies-aoc-town-hall-pro-trump-troll-larouche'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_ft.url.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>www.buzzfeednews.com/article/tasneemnashrulla/...</td>\n",
       "      <td>\"Eat The Babies\" Viral Video At AOC Town Hall ...</td>\n",
       "      <td>Oct 4, 2019</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>pro</td>\n",
       "      <td>cc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "4539  www.buzzfeednews.com/article/tasneemnashrulla/...   \n",
       "\n",
       "                                                  title         date  \\\n",
       "4539  \"Eat The Babies\" Viral Video At AOC Town Hall ...  Oct 4, 2019   \n",
       "\n",
       "        domain stance topic is_AP  \n",
       "4539  buzzfeed    pro    cc  None  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.loc[combined_df.url.isin(urls_ft_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = [x for x in url_unique_keys if 'adultvaccinesnow' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adultvaccinesnow.org/blog/2016/12/09/2016-start-making-a-difference-2017-take-it-to-the-next-level/',\n",
       " 'adultvaccinesnow.org/blog/2016/05/25/avac-celebrates-older-americans-month/',\n",
       " 'adultvaccinesnow.org/blog/2019/05/16/avac-spotlight-amy-pisani-vaccinate-your-family/',\n",
       " 'adultvaccinesnow.org/blog/2019/03/04/avac-spotlight-andrea-polkinghorn-sanford-health-sioux-falls-sd/',\n",
       " 'adultvaccinesnow.org/blog/2017/09/25/avac-spotlight-creative-solutions-addressing-vaccine-disparities/',\n",
       " 'adultvaccinesnow.org/blog/2019/03/20/avac-spotlight-dara-lieberman-trust-for-americas-health/',\n",
       " 'adultvaccinesnow.org/blog/2017/11/29/avac-spotlight-dr-kelly-moore-and-the-tn-immunization-program/',\n",
       " 'adultvaccinesnow.org/blog/2017/12/13/avac-spotlight-dr-minerva-campos-family-physician-and-board-member-of-the-national-hispanic-medical-association/',\n",
       " 'adultvaccinesnow.org/blog/2018/04/16/avac-spotlight-dr-wilbur-h-chen-associate-professor-of-medicine-and-chief-of-the-adult-clinical-studies-section-center-for-vaccine-development-university-of-maryland-school-of-medicine/',\n",
       " 'adultvaccinesnow.org/blog/2018/03/08/avac-spotlight-lauren-linkenauger-pharmd/',\n",
       " 'adultvaccinesnow.org/blog/2018/05/30/avac-spotlight-litjen-l-j-tan-ms-phd-chief-strategy-officer-of-immunization-action-coalition/',\n",
       " 'adultvaccinesnow.org/blog/2018/04/02/avac-spotlight-michael-popovich-ceo-scientific-technologies-corporation-stc/',\n",
       " 'adultvaccinesnow.org/blog/2018/06/20/avac-spotlight-robert-h-hopkins-jr-md-professor-of-medicine-and-pediatrics-and-director-of-division-of-general-internal-medicine-department-of-internal-medicine-university-of-arkansas-for-med/',\n",
       " 'adultvaccinesnow.org/blog/2018/08/01/avac-spotlight-sarah-irsik-good-mha-president-and-ceo-of-the-kansas-foundation-for-medical-care/',\n",
       " 'adultvaccinesnow.org/blog/2018/10/26/avac-spotlight-serese-marotta-families-fighting-flu-fff/',\n",
       " 'adultvaccinesnow.org/blog/2017/11/07/avac-spotlight-utilizing-standing-orders-to-generate-system-change/',\n",
       " 'adultvaccinesnow.org/blog/2016/05/20/avac-and-the-next-frontier-for-immunizations-by-dale-dauten/',\n",
       " 'adultvaccinesnow.org/blog/2015/09/30/adult-vaccination-rates-too-low-putting-our-nations-health-and-pocketbook-at-risk-says-new-coalition/',\n",
       " 'adultvaccinesnow.org/blog/2015/11/05/adult-vaccine-access-coalition-launches-to-rally-efforts-to-increase-adult-immunization-rates/',\n",
       " 'adultvaccinesnow.org/blog/2015/10/16/barriers-to-accessing-adult-vaccines/',\n",
       " 'adultvaccinesnow.org/blog/2018/02/27/building-a-strong-vaccine-infrastructure/',\n",
       " 'adultvaccinesnow.org/blog/2016/04/19/congresswoman-eddie-bernice-johnson-joins-congressman-ami-bera-and-congresswoman-michelle-lujan-grisham-to-call-for-a-reduction-in-financial-barriers-to-vaccines/',\n",
       " 'adultvaccinesnow.org/blog/2016/04/21/every-american-should-have-access-to-life-saving-vaccines/',\n",
       " 'adultvaccinesnow.org/blog/2018/03/06/healthy-aging-and-immunizations-full-video-from-our-briefing/',\n",
       " 'adultvaccinesnow.org/blog/2019/02/04/healthy-people-2030/',\n",
       " 'adultvaccinesnow.org/blog/2015/10/08/making-the-case-for-covering-the-flu-vaccine/',\n",
       " 'adultvaccinesnow.org/blog/2019/06/14/measles-madness-and-value-gene-therapy-prevention-and-the-pre-vaccine-era/',\n",
       " 'adultvaccinesnow.org/blog/2019/09/24/moving-more-electrons-to-optimize-new-adult-composite-immunization-measures/',\n",
       " 'adultvaccinesnow.org/blog/2017/03/09/op-ed-making-vaccine-preventable-diseases-history/',\n",
       " 'adultvaccinesnow.org/blog/2018/09/26/outbreak-diy-epidemics-in-a-connected-world/',\n",
       " 'adultvaccinesnow.org/blog/2018/09/17/promoting-access-starts-with-educating-people-about-need/',\n",
       " 'adultvaccinesnow.org/blog/2015/12/18/protecting-americans-from-infectious-diseases/',\n",
       " 'adultvaccinesnow.org/blog/2016/08/29/quality-over-quantity-making-the-case-for-vaccines-michael-hodin-ph-d-and-william-shaftner-m-d-discuss-in-op-ed/',\n",
       " 'adultvaccinesnow.org/blog/2017/08/15/recognizing-innovation-avac-spotlight/',\n",
       " 'adultvaccinesnow.org/blog/2020/02/10/the-essential-role-of-physicians-in-immunization/',\n",
       " 'adultvaccinesnow.org/blog/2017/08/01/the-essential-role-of-public-health-in-immunization-avac-spotlight/',\n",
       " 'adultvaccinesnow.org/blog/2016/04/18/the-importance-of-adult-immunizations-op-ed-by-rep-gene-green-d-texas-and-dr-litjen-tan/',\n",
       " 'adultvaccinesnow.org/blog/2016/02/25/u-s-congresswoman-roybal-allard-raises-critical-questions-on-adult-vaccine-access/',\n",
       " 'adultvaccinesnow.org/blog/2019/08/21/vaccinate-your-family-mourns-the-loss-of-rich-greenaway/',\n",
       " 'adultvaccinesnow.org/blog/2020/01/21/vaccine-infrastructure-and-education-is-the-best-medical-investment-our-country-can-make/']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also combine w/ my existing articles \n",
    "# 1(all_url_df--shoot for 10k on each side for cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dedup via title similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to get missing titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_title_date(soup,domain):\n",
    "    if domain == 'buzzfeed':\n",
    "        title = soup.find('h1').text.strip()\n",
    "        try:\n",
    "            date = parse(soup.find('time').text\\\n",
    "                         .split('Posted on ')[-1].split(' - ')[-1].split(', ')[0].strip())\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                date = parse(soup.find('time').text.strip())\n",
    "            except AttributeError:\n",
    "                date = parse(soup.find('div',attrs={'class':'news-article-header__timestamps'}).text\\\n",
    "            .split('Posted on ')[-1].split(' - ')[-1].split(', ')[0].strip())\n",
    "    elif domain == 'dem_now':\n",
    "        title = soup.find('h1').text.strip()\n",
    "        date = parse(soup.find('span',attrs={'class':'date'}).text.strip())\n",
    "    elif domain == 'the_nation':\n",
    "        title = soup.find('h1',attrs={'class':'title'}).text.strip()\n",
    "        date = parse(soup.find('h4').text.strip())\n",
    "    elif domain == 'wapo':\n",
    "        title = soup.find('h1').text.strip()\n",
    "        date = parse(soup.find('div',attrs={'class':'display-date'}).text.strip())\n",
    "    elif domain == 'vox':\n",
    "        title = soup.find('h1').text.strip()\n",
    "        try:\n",
    "            date = soup.find('time')['datetime']\n",
    "        except TypeError:\n",
    "            date = None\n",
    "    elif domain == 'the_progressive':\n",
    "        title = soup.find('h1').text.strip()\n",
    "        date = soup.find('time')['datetime']\n",
    "    else:\n",
    "        title,date = None,None\n",
    "        \n",
    "    return (title,date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Information on URLs, media domains, stance, and topic is all complete.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(combined_df.loc[pd.isnull(combined_df.url)]) == 0\n",
    "assert len(combined_df.loc[pd.isnull(combined_df.domain)]) == 0\n",
    "assert len(combined_df.loc[pd.isnull(combined_df.stance)]) == 0\n",
    "assert len(combined_df.loc[pd.isnull(combined_df.topic)]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_title_df = combined_df.loc[pd.isnull(combined_df.title)]\n",
    "missing_title_df.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,ix in enumerate(missing_title_df.index):\n",
    "    row = missing_title_df.loc[ix]\n",
    "    url = row['url']\n",
    "    domain = row['domain']\n",
    "    soup = soupify(url)\n",
    "    title,date = get_title_date(soup,domain)\n",
    "    combined_df.loc[ix]['title'] = title\n",
    "    combined_df.loc[ix]['date'] = date\n",
    "    if n % 100 == 0:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.loc[pd.isnull(combined_df.title)].shape)\n",
    "print(combined_df.loc[pd.isnull(combined_df.date)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the heuristic as described in Petersen et al. to deduplicate articles based on titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def d_l_dist(s1, s2):\n",
    "    d = {}\n",
    "    lenstr1 = len(s1)\n",
    "    lenstr2 = len(s2)\n",
    "    for i in range(-1,lenstr1+1):\n",
    "        d[(i,-1)] = i+1\n",
    "    for j in range(-1,lenstr2+1):\n",
    "        d[(-1,j)] = j+1\n",
    "\n",
    "    for i in range(lenstr1):\n",
    "        for j in range(lenstr2):\n",
    "            if s1[i] == s2[j]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[(i,j)] = min(\n",
    "                           d[(i-1,j)] + 1, # deletion\n",
    "                           d[(i,j-1)] + 1, # insertion\n",
    "                           d[(i-1,j-1)] + cost, # substitution\n",
    "                          )\n",
    "            if i and j and s1[i]==s2[j-1] and s1[i-1] == s2[j]:\n",
    "                d[(i,j)] = min (d[(i,j)], d[i-2,j-2] + cost) # transposition\n",
    "\n",
    "    return d[lenstr1-1,lenstr2-1]\n",
    "\n",
    "def is_same(u1,u2):\n",
    "    #Djk0.2Min.[|Tj|,|Tk|]\n",
    "    # determine Damerau-Levensthtein edit distance\n",
    "    D_jk = d_l_dist(u1,u2)\n",
    "    t_j = len(u1)\n",
    "    t_k = len(u2)\n",
    "    min_ = min(t_j,t_k)\n",
    "    return D_jk < 0.2*min_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_groups = combined_df.groupby('domain')\n",
    "outlet_groups.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually, improve how I save indices to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outlet in outlet_groups.first().index[4:]:\n",
    "    outlet_df = outlet_groups.get_group(outlet)\n",
    "    print('Processing {} with {} URLS'.format(outlet,len(outlet_df)))\n",
    "    outlet_titles = outlet_df.title.values\n",
    "    for ix1 in range(len(outlet_titles)-1):\n",
    "        for ix2 in range(ix1+1,len(outlet_titles)):\n",
    "            t1 = outlet_titles[ix1]\n",
    "            t2 = outlet_titles[ix2]\n",
    "            #print(t1,t2)\n",
    "            if is_same(t1,t2):\n",
    "                to_remove.append((outlet_df.index[outlet_df['title'] == t1],\n",
    "                                 outlet_df.index[outlet_df['title'] == t2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(to_remove,open('dups_to_remove.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude articles w/ empty fulltext in final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
